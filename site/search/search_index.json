{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ORCA - Orchestration for Research Cloud Access","text":"<p>ORCA enables research institutions to seamlessly burst Kubernetes workloads from on-premises Kubernetes clusters to AWS, with native support for GPU-intensive AI/ML computing.</p>"},{"location":"#what-is-orca","title":"What is ORCA?","text":"<p>ORCA (Orchestration for Research Cloud Access) is a Kubernetes Virtual Kubelet provider that allows research Kubernetes clusters to dynamically extend capacity to AWS when local resources are exhausted.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>\ud83c\udf93 Research-First Design - Built for academic and research workloads</li> <li>\ud83d\udda5\ufe0f AI/ML Accelerators - Support for NVIDIA GPUs (P6, P5, P4d, G6e), AWS Trainium, Inferentia, and FPGAs</li> <li>\ud83c\udfaf Explicit Control - Users specify exact instance types, not guessed</li> <li>\ud83d\udcb0 Cost-Aware - Budget controls, cost tracking, spot instance support</li> <li>\ud83d\udd13 Open Source - Apache 2.0 licensed, community-driven</li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li> <p> Getting Started</p> <p>Get ORCA up and running in minutes</p> <p> Quick Start</p> </li> <li> <p> User Guide</p> <p>Learn how to use ORCA for your workloads</p> <p> User Guide</p> </li> <li> <p> Architecture</p> <p>Understand how ORCA works</p> <p> Architecture</p> </li> <li> <p> Development</p> <p>Contribute to ORCA development</p> <p> Development</p> </li> </ul>"},{"location":"#architecture-overview","title":"Architecture Overview","text":"<pre><code>graph TB\n    subgraph \"Research Cluster\"\n        K8S[Kubernetes API]\n        VK[ORCA Virtual Kubelet]\n        POD[Pod with GPU Request]\n    end\n\n    subgraph \"AWS\"\n        EC2[EC2 Instance&lt;br/&gt;P5.48xlarge&lt;br/&gt;8x H100 GPUs]\n        SPOT[Spot Instances]\n        CR[Capacity Reservations]\n    end\n\n    POD --&gt;|Schedule| VK\n    VK --&gt;|Register| K8S\n    VK --&gt;|Launch| EC2\n    VK -.-&gt;|Optional| SPOT\n    VK -.-&gt;|Preferred| CR\n\n    style VK fill:#4285f4,stroke:#333,stroke-width:2px,color:#fff\n    style EC2 fill:#ff9900,stroke:#333,stroke-width:2px\n    style POD fill:#326ce5,stroke:#333,stroke-width:2px,color:#fff</code></pre>"},{"location":"#use-cases","title":"Use Cases","text":""},{"location":"#aiml-training","title":"AI/ML Training","text":"<p>Burst large model training to AWS GPUs, Trainium, or Inferentia when local clusters are full.</p>"},{"location":"#cost-optimized-computing","title":"Cost-Optimized Computing","text":"<p>Use Trainium for 50% lower training costs or Inferentia for 70% lower inference costs compared to GPUs.</p>"},{"location":"#research-computing","title":"Research Computing","text":"<p>Access specialized hardware on-demand: FPGAs for genomics, latest GPUs for deep learning.</p>"},{"location":"#multi-tenant-research","title":"Multi-Tenant Research","text":"<p>Support multiple departments with separate budgets and cost tracking.</p>"},{"location":"#why-orca","title":"Why ORCA?","text":""},{"location":"#vs-elotl-kip","title":"vs. Elotl Kip","text":"<ul> <li>Kip is EOL (last updated 2021) - stuck on K8s 1.18, AWS SDK v1</li> <li>ORCA is modern - K8s 1.34, AWS SDK v2, Go 1.25, latest instance types (P6, G6e)</li> <li>ORCA prioritizes explicit control - users know their requirements</li> </ul>"},{"location":"#vs-aws-fargate-virtual-kubelet","title":"vs. AWS Fargate Virtual Kubelet","text":"<ul> <li>Fargate provider is unmaintained and doesn't support GPUs</li> <li>ORCA is GPU-first - built for AI/ML research</li> </ul>"},{"location":"#vs-building-on-managed-k8s","title":"vs. Building on Managed K8s","text":"<ul> <li>ORCA extends existing Kubernetes clusters - research institutions already have K8s</li> <li>No migration needed - burst workloads, keep existing infrastructure</li> </ul>"},{"location":"#project-status","title":"Project Status","text":"<p>Current Phase: Alpha Development</p> <p>\u26a0\ufe0f ALPHA SOFTWARE - ORCA is under active development. Container execution is not yet implemented (Issue #8). Pods will be scheduled and EC2 instances will launch, but containers will not run.</p>"},{"location":"#what-works-today","title":"What Works Today \u2705","text":"<ul> <li>Virtual Kubelet node registration and heartbeat</li> <li>EC2 instance lifecycle (create, terminate, query status)</li> <li>Instance selection (explicit, template, auto) - fully tested</li> <li>HTTP server with /healthz, /readyz, /metrics endpoints</li> <li>Configuration validation and AWS SDK integration</li> </ul>"},{"location":"#what-doesnt-work-yet","title":"What Doesn't Work Yet \u274c","text":"<ul> <li>Container execution (Issue #8) - \ud83d\udd34 CRITICAL BLOCKER</li> <li>kubectl logs (Issue #9) - requires container runtime</li> <li>kubectl exec (Issue #10) - requires container runtime</li> <li>GPU workloads - requires container runtime</li> <li>Pod networking - requires container runtime</li> <li>Volume mounting - requires container runtime</li> <li>Metrics collection (Issue #11)</li> </ul>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>\ud83c\udfaf Priority 1: Container Runtime Integration (Issue #8)</li> <li>\ud83c\udfaf Priority 2: kubectl logs/exec (Issues #9, #10)</li> <li>\ud83c\udfaf Priority 3: GPU Support and Capacity Reservations (Issue #12)</li> </ul>"},{"location":"#roadmap","title":"Roadmap","text":"<p>ORCA development follows a phased approach aligned with research computing needs. Track our progress on the GitHub project board.</p>"},{"location":"#phase-1-mvp-complete","title":"Phase 1: MVP \u2705 Complete","text":"<p>Months 1-3</p> <p>Core Virtual Kubelet provider with basic pod-to-EC2 mapping and explicit instance selection. Simple lifecycle management.</p> <p>Status: Implementation complete, metrics in progress</p>"},{"location":"#phase-2-production-features-in-progress","title":"Phase 2: Production Features \ud83d\udea7 In Progress","text":"<p>Months 4-6</p> <p>Production-ready features including: - GPU support for all NVIDIA instance types (P6, P5, P4d, G6e) - Container runtime integration with containerd - kubectl logs and exec via CloudWatch and Systems Manager - Spot instance support for cost optimization</p> <p>View Phase 2 issues \u2192</p>"},{"location":"#phase-3-nrp-integration-planned","title":"Phase 3: NRP Integration \u23f3 Planned","text":"<p>Months 7-9</p> <p>National Research Platform integration: - Automatic Ceph storage mounting - NRP namespace awareness and identity - Multi-tenancy with per-namespace quotas - Cost tracking and budget enforcement</p> <p>View Phase 3 issues \u2192</p>"},{"location":"#phase-4-advanced-features-future","title":"Phase 4: Advanced Features \u23f3 Future","text":"<p>Months 9+</p> <p>Enterprise and advanced capabilities: - Intelligent scheduling algorithms - Capacity planning and forecasting - Compliance features (HIPAA, FedRAMP) - Multi-region support</p> <p>View Phase 4 issues \u2192</p> <p>View all milestones \u2192</p>"},{"location":"#community","title":"Community","text":"<ul> <li>Website: orcapod.dev</li> <li>GitHub: scttfrdmn/orca</li> <li>Issues: Report bugs or request features</li> <li>Discussions: Questions and ideas</li> <li>License: Apache 2.0</li> </ul>"},{"location":"#getting-help","title":"Getting Help","text":"<ul> <li>\ud83d\udcd6 Read the docs</li> <li>\ud83d\udc1b Report issues</li> <li>\ud83d\udcac Discussions</li> <li>\ud83e\udd1d Contributing guide</li> </ul> <p>Built with \ud83c\udf0a for research computing</p>"},{"location":"CONTRIBUTING/","title":"Contributing to ORCA","text":"<p>Thank you for your interest in contributing to ORCA! We welcome contributions from the community.</p>"},{"location":"CONTRIBUTING/#getting-started","title":"Getting Started","text":""},{"location":"CONTRIBUTING/#prerequisites","title":"Prerequisites","text":"<ul> <li>Go 1.21 or higher</li> <li>Docker (for containerized testing)</li> <li>kubectl (for Kubernetes testing)</li> <li>AWS account (for integration testing)</li> <li>golangci-lint (for linting)</li> </ul>"},{"location":"CONTRIBUTING/#development-setup","title":"Development Setup","text":"<ol> <li> <p>Clone the repository <pre><code>git clone https://github.com/scttfrdmn/orca.git\ncd orca\n</code></pre></p> </li> <li> <p>Install dependencies <pre><code>make mod-download\n</code></pre></p> </li> <li> <p>Install development tools <pre><code># Install golangci-lint\ngo install github.com/golangci/golangci-lint/cmd/golangci-lint@latest\n</code></pre></p> </li> <li> <p>Build the project <pre><code>make build\n</code></pre></p> </li> <li> <p>Run tests <pre><code>make test\n</code></pre></p> </li> </ol>"},{"location":"CONTRIBUTING/#development-workflow","title":"Development Workflow","text":""},{"location":"CONTRIBUTING/#making-changes","title":"Making Changes","text":"<ol> <li> <p>Create a feature branch <pre><code>git checkout -b feature/your-feature-name\n</code></pre></p> </li> <li> <p>Make your changes</p> </li> <li>Write idiomatic Go code</li> <li>Follow the project structure conventions</li> <li>Add tests for new functionality</li> <li> <p>Update documentation as needed</p> </li> <li> <p>Format and lint <pre><code>make fmt\nmake lint\nmake vet\n</code></pre></p> </li> <li> <p>Run tests <pre><code>make test\nmake coverage\n</code></pre></p> </li> <li> <p>Commit your changes <pre><code>git add .\ngit commit -m \"feat: add new feature\"\n</code></pre></p> </li> </ol>"},{"location":"CONTRIBUTING/#commit-message-convention","title":"Commit Message Convention","text":"<p>We follow Conventional Commits:</p> <ul> <li><code>feat:</code> - New feature</li> <li><code>fix:</code> - Bug fix</li> <li><code>docs:</code> - Documentation changes</li> <li><code>test:</code> - Adding or updating tests</li> <li><code>refactor:</code> - Code refactoring</li> <li><code>perf:</code> - Performance improvements</li> <li><code>chore:</code> - Maintenance tasks</li> </ul> <p>Examples: <pre><code>feat: add explicit instance selection support\nfix: handle pod deletion edge cases\ndocs: update instance selection guide\ntest: add unit tests for AWS client\n</code></pre></p>"},{"location":"CONTRIBUTING/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Update documentation - Ensure README.md and relevant docs are updated</li> <li>Add changelog entry - Add your changes to CHANGELOG.md under [Unreleased]</li> <li>Ensure tests pass - All tests must pass (<code>make test</code>)</li> <li>Ensure linting passes - Code must pass linting (<code>make lint</code>)</li> <li>Create pull request - Provide clear description of changes</li> <li>Request review - Tag maintainers for review</li> </ol>"},{"location":"CONTRIBUTING/#code-style-guidelines","title":"Code Style Guidelines","text":""},{"location":"CONTRIBUTING/#go-code-style","title":"Go Code Style","text":"<ul> <li>Follow Effective Go</li> <li>Use <code>gofmt</code> for formatting (run <code>make fmt</code>)</li> <li>Keep functions focused and small</li> <li>Write self-documenting code with clear variable names</li> <li>Add comments for exported functions and complex logic</li> </ul>"},{"location":"CONTRIBUTING/#error-handling","title":"Error Handling","text":"<pre><code>// Good: Wrap errors with context\nif err != nil {\n    return fmt.Errorf(\"failed to create instance: %w\", err)\n}\n\n// Bad: Generic error\nif err != nil {\n    return err\n}\n</code></pre>"},{"location":"CONTRIBUTING/#logging","title":"Logging","text":"<pre><code>// Use structured logging\nlog.Info(\"creating pod\",\n    \"namespace\", pod.Namespace,\n    \"name\", pod.Name,\n    \"instanceType\", instanceType)\n</code></pre>"},{"location":"CONTRIBUTING/#testing-guidelines","title":"Testing Guidelines","text":""},{"location":"CONTRIBUTING/#unit-tests","title":"Unit Tests","text":"<ul> <li>Write tests for all new functionality</li> <li>Aim for &gt;80% code coverage</li> <li>Use table-driven tests where appropriate</li> <li>Mock external dependencies (AWS SDK, Kubernetes API)</li> </ul> <p>Example: <pre><code>func TestSelectInstanceType(t *testing.T) {\n    tests := []struct {\n        name     string\n        pod      *corev1.Pod\n        expected string\n    }{\n        {\n            name: \"explicit instance type\",\n            pod: &amp;corev1.Pod{\n                ObjectMeta: metav1.ObjectMeta{\n                    Annotations: map[string]string{\n                        \"orca.research/instance-type\": \"p5.48xlarge\",\n                    },\n                },\n            },\n            expected: \"p5.48xlarge\",\n        },\n        // More test cases...\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            result := selectInstanceType(tt.pod)\n            if result != tt.expected {\n                t.Errorf(\"expected %s, got %s\", tt.expected, result)\n            }\n        })\n    }\n}\n</code></pre></p>"},{"location":"CONTRIBUTING/#integration-tests","title":"Integration Tests","text":"<ul> <li>Test against real AWS services when possible</li> <li>Use AWS localstack for local testing</li> <li>Clean up resources after tests</li> </ul>"},{"location":"CONTRIBUTING/#documentation","title":"Documentation","text":""},{"location":"CONTRIBUTING/#code-documentation","title":"Code Documentation","text":"<ul> <li>Document all exported functions, types, and constants</li> <li>Use godoc format</li> </ul> <pre><code>// CreatePod creates a new pod by launching an EC2 instance.\n// It returns an error if the instance cannot be created.\nfunc (p *Provider) CreatePod(ctx context.Context, pod *corev1.Pod) error {\n    // Implementation\n}\n</code></pre>"},{"location":"CONTRIBUTING/#user-documentation","title":"User Documentation","text":"<ul> <li>Update README.md for user-facing changes</li> <li>Add examples in <code>examples/</code> directory</li> <li>Update relevant docs in <code>docs/</code> directory</li> </ul>"},{"location":"CONTRIBUTING/#architecture-guidelines","title":"Architecture Guidelines","text":""},{"location":"CONTRIBUTING/#project-structure","title":"Project Structure","text":"<pre><code>cmd/orca/           # Main application entry point\npkg/                # Public libraries\n  provider/         # Virtual Kubelet provider implementation\n  config/           # Configuration management\n  instances/        # Instance selection logic\ninternal/           # Private application code\n  aws/              # AWS SDK integration\n  container/        # Container runtime integration\n  metrics/          # Metrics and monitoring\n</code></pre>"},{"location":"CONTRIBUTING/#design-principles","title":"Design Principles","text":"<ol> <li>Explicit over Implicit - Users should specify what they want</li> <li>Research-First - Optimize for research computing workflows</li> <li>Production-Grade - Write code as if it will run at scale</li> <li>Testability - Design for testability from the start</li> <li>Observability - Include metrics, logging, tracing</li> </ol>"},{"location":"CONTRIBUTING/#getting-help","title":"Getting Help","text":"<ul> <li>GitHub Issues - Bug reports and feature requests</li> <li>GitHub Discussions - Questions and general discussion</li> <li>Research Partners - Reach out to NRP, SDSU contacts</li> </ul>"},{"location":"CONTRIBUTING/#code-of-conduct","title":"Code of Conduct","text":"<ul> <li>Be respectful and inclusive</li> <li>Focus on constructive feedback</li> <li>Welcome newcomers</li> <li>Assume good intentions</li> </ul>"},{"location":"CONTRIBUTING/#license","title":"License","text":"<p>By contributing to ORCA, you agree that your contributions will be licensed under the Apache License 2.0.</p>"},{"location":"api/","title":"API Reference","text":"<p>Reference documentation for ORCA annotations, configuration, and metrics.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"api/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"api/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"api/annotations/","title":"Pod Annotations","text":"<p>Complete reference of ORCA pod annotations.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"api/annotations/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"api/annotations/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"api/configuration/","title":"Configuration Reference","text":"<p>Complete configuration options for ORCA.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"api/configuration/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"api/configuration/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"api/metrics/","title":"Metrics Reference","text":"<p>Prometheus metrics exposed by ORCA.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"api/metrics/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"api/metrics/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"architecture/","title":"Architecture","text":"<p>ORCA's architecture and design principles.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"architecture/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"architecture/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"architecture/aws-integration/","title":"AWS Integration","text":"<p>How ORCA integrates with AWS EC2 and other services.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"architecture/aws-integration/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"architecture/aws-integration/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"architecture/design-decisions/","title":"Design Decisions","text":"<p>Key architectural decisions and trade-offs.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"architecture/design-decisions/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"architecture/design-decisions/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"architecture/instance-selection/","title":"Instance Selection Architecture","text":"<p>How ORCA selects EC2 instances (explicit, template, auto).</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"architecture/instance-selection/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"architecture/instance-selection/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"architecture/overview/","title":"Architecture Overview","text":"<p>High-level overview of how ORCA works.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"architecture/overview/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"architecture/overview/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"architecture/pod-lifecycle/","title":"Pod Lifecycle","text":"<p>How ORCA manages pod lifecycle from creation to termination.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"architecture/pod-lifecycle/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"architecture/pod-lifecycle/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"architecture/virtual-kubelet/","title":"Virtual Kubelet Integration","text":"<p>This document describes ORCA's Virtual Kubelet integration, which enables ORCA to register as a Kubernetes node and handle pod lifecycle events.</p>"},{"location":"architecture/virtual-kubelet/#overview","title":"Overview","text":"<p>ORCA uses the Virtual Kubelet framework to present itself as a node in a Kubernetes cluster. When pods are scheduled to the ORCA node, they are executed as EC2 instances on AWS rather than as containers on a physical node.</p>"},{"location":"architecture/virtual-kubelet/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Kubernetes Control Plane                \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                         \u2502\n\u2502 \u2502  Scheduler  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502          \u2502\n\u2502                               \u25bc          \u2502\n\u2502                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502                        \u2502  API Server  \u2502 \u2502\n\u2502                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n                                \u2502 Watch Pods\n                                \u2502 Update Status\n                                \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502   ORCA Virtual Node   \u2502\n                    \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n                    \u2502 \u2502 Node Controller   \u2502 \u2502\n                    \u2502 \u2502 - Register Node   \u2502 \u2502\n                    \u2502 \u2502 - Watch Pods      \u2502 \u2502\n                    \u2502 \u2502 - Update Status   \u2502 \u2502\n                    \u2502 \u2502 - Manage Lease    \u2502 \u2502\n                    \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n                    \u2502          \u2502            \u2502\n                    \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n                    \u2502 \u2502 VK Adapter        \u2502 \u2502\n                    \u2502 \u2502 - CreatePod       \u2502 \u2502\n                    \u2502 \u2502 - DeletePod       \u2502 \u2502\n                    \u2502 \u2502 - GetPodStatus    \u2502 \u2502\n                    \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n                    \u2502          \u2502            \u2502\n                    \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n                    \u2502 \u2502 ORCA Provider     \u2502 \u2502\n                    \u2502 \u2502 - Instance Mgmt   \u2502 \u2502\n                    \u2502 \u2502 - AWS Client      \u2502 \u2502\n                    \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                               \u2502\n                               \u2502 EC2 API\n                               \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502   AWS EC2             \u2502\n                    \u2502 \u250c\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2510 \u2502\n                    \u2502 \u2502 i1 \u2502 \u2502 i2 \u2502 \u2502 i3 \u2502 \u2502\n                    \u2502 \u2514\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2518 \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/virtual-kubelet/#components","title":"Components","text":""},{"location":"architecture/virtual-kubelet/#pkgnodecontrollergo","title":"pkg/node/controller.go","text":"<p>The <code>Controller</code> manages the Virtual Kubelet node lifecycle:</p> <ul> <li>Initialization: Creates Kubernetes client, ORCA provider, and Virtual Kubelet components</li> <li>Node Registration: Registers the virtual node with the Kubernetes API server</li> <li>Lease Management: Maintains node heartbeat via Kubernetes lease mechanism (40s intervals)</li> <li>Graceful Shutdown: Handles SIGTERM/SIGINT with proper cleanup</li> </ul> <p>Key Methods: <pre><code>// NewController creates a new node controller\nfunc NewController(cfg *config.Config, kubeconfigPath, namespace, version string, logger zerolog.Logger) (*Controller, error)\n\n// Run starts the Virtual Kubelet node controller\nfunc (c *Controller) Run(ctx context.Context) error\n\n// Shutdown gracefully shuts down the controller\nfunc (c *Controller) Shutdown(ctx context.Context) error\n</code></pre></p>"},{"location":"architecture/virtual-kubelet/#pkgnodeadaptergo","title":"pkg/node/adapter.go","text":"<p>The <code>VirtualKubeletAdapter</code> implements the Virtual Kubelet <code>PodLifecycleHandler</code> interface, bridging between Virtual Kubelet and the ORCA provider:</p> <p>Pod Lifecycle Methods: - <code>CreatePod</code>: Called when Kubernetes schedules a pod to this node - <code>UpdatePod</code>: Called when pod spec is updated - <code>DeletePod</code>: Called when pod is deleted - <code>GetPod</code>: Retrieves pod by namespace/name - <code>GetPods</code>: Lists all pods on this node - <code>GetPodStatus</code>: Gets current pod status</p> <p>Exec/Logs Methods: - <code>GetContainerLogs</code>: Retrieves container logs (TODO: implement via CloudWatch) - <code>RunInContainer</code>: Executes commands in container (TODO: implement via SSM)</p> <p>Node Methods: - <code>ConfigureNode</code>: Sets node capacity, labels, taints - <code>NotifyNodeStatus</code>: Callback for node status updates - <code>Ping</code>: Health check for provider responsiveness</p>"},{"location":"architecture/virtual-kubelet/#pod-lifecycle-flow","title":"Pod Lifecycle Flow","text":""},{"location":"architecture/virtual-kubelet/#1-pod-creation","title":"1. Pod Creation","text":"<pre><code>User submits pod \u2192 Scheduler assigns to orca-aws-node \u2192 \nCreatePod called \u2192 Instance selector chooses type \u2192\nEC2 instance launched \u2192 Pod status updated to Running\n</code></pre> <p>Code Flow: <pre><code>// 1. Virtual Kubelet calls CreatePod\nadapter.CreatePod(ctx, pod)\n  \u2193\n// 2. ORCA provider handles creation\nprovider.CreatePod(ctx, pod)\n  \u2193\n// 3. Select instance type from annotations\nselector.Select(pod) // Returns \"p5.48xlarge\"\n  \u2193\n// 4. Launch EC2 instance\nawsClient.CreateInstance(ctx, pod, instanceType)\n  \u2193\n// 5. Tag instance with pod metadata\nbuildInstanceTags(pod, instanceType)\n  \u2193\n// 6. Wait for instance running state\nwaiter.Wait(ctx, instanceID, 5*time.Minute)\n  \u2193\n// 7. Update pod status\npod.Status.Phase = corev1.PodRunning\npod.Status.HostIP = instance.PublicIP\n</code></pre></p>"},{"location":"architecture/virtual-kubelet/#2-pod-monitoring","title":"2. Pod Monitoring","text":"<p>ORCA continuously syncs pod status with EC2 instance state:</p> <pre><code>// Virtual Kubelet periodically calls GetPodStatus\nstatus := provider.GetPodStatus(ctx, namespace, name)\n  \u2193\n// Query EC2 instance state\ninstance := awsClient.GetInstanceByPod(ctx, namespace, name)\n  \u2193\n// Map EC2 state to Pod phase\nswitch instance.State {\ncase \"running\":  \u2192 corev1.PodRunning\ncase \"pending\":  \u2192 corev1.PodPending\ncase \"stopped\":  \u2192 corev1.PodFailed\n}\n</code></pre>"},{"location":"architecture/virtual-kubelet/#3-pod-deletion","title":"3. Pod Deletion","text":"<pre><code>kubectl delete pod \u2192 DeletePod called \u2192\nFind EC2 instance by tags \u2192 Terminate instance \u2192\nPod removed from tracking\n</code></pre> <p>Code Flow: <pre><code>adapter.DeletePod(ctx, pod)\n  \u2193\nprovider.DeletePod(ctx, pod)\n  \u2193\n// Find instance by pod tags\ninstance := awsClient.GetInstanceByPod(ctx, pod.Namespace, pod.Name)\n  \u2193\n// Terminate instance\nawsClient.TerminateInstance(ctx, instance.ID)\n  \u2193\n// Remove from internal tracking\ndelete(provider.pods, pod.UID)\n</code></pre></p>"},{"location":"architecture/virtual-kubelet/#node-configuration","title":"Node Configuration","text":"<p>The virtual node is configured via <code>config.yaml</code>:</p> <pre><code>node:\n  name: orca-aws-node\n\n  labels:\n    orca.research/provider: \"aws\"\n    orca.research/region: \"us-west-2\"\n    type: virtual-kubelet\n\n  taints:\n    - key: orca.research/burst-node\n      value: \"true\"\n      effect: NoSchedule\n\n  operatingSystem: Linux\n\n  # Aggregate capacity (upper bounds)\n  cpu: \"1000\"      # 1000 vCPUs\n  memory: \"4Ti\"    # 4 TiB\n  pods: \"1000\"     # Max 1000 pods\n  gpu: \"100\"       # Max 100 GPUs\n</code></pre> <p>Node Labels: - <code>orca.research/provider: aws</code> - Identifies ORCA nodes - <code>orca.research/region: us-west-2</code> - AWS region - <code>type: virtual-kubelet</code> - Standard Virtual Kubelet label</p> <p>Node Taints: - <code>orca.research/burst-node=true:NoSchedule</code> - Prevents regular pods from scheduling   - Pods must explicitly tolerate this taint to burst to AWS</p>"},{"location":"architecture/virtual-kubelet/#pod-annotations","title":"Pod Annotations","text":"<p>Pods control their EC2 instance configuration via annotations:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: gpu-training\n  annotations:\n    # Required: Explicit instance type selection\n    orca.research/instance-type: \"p5.48xlarge\"\n\n    # Optional: Launch type (on-demand or spot)\n    orca.research/launch-type: \"spot\"\n\n    # Optional: Max spot price ($/hour)\n    orca.research/max-spot-price: \"35.00\"\n\n    # Optional: Custom AMI\n    orca.research/ami: \"ami-0123456789abcdef0\"\nspec:\n  nodeSelector:\n    orca.research/provider: \"aws\"\n\n  tolerations:\n    - key: orca.research/burst-node\n      operator: Equal\n      value: \"true\"\n      effect: NoSchedule\n\n  containers:\n    - name: trainer\n      image: pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime\n      resources:\n        limits:\n          nvidia.com/gpu: 8\n</code></pre>"},{"location":"architecture/virtual-kubelet/#kubernetes-connection","title":"Kubernetes Connection","text":"<p>ORCA supports three methods for connecting to Kubernetes:</p>"},{"location":"architecture/virtual-kubelet/#1-in-cluster-configuration-production","title":"1. In-Cluster Configuration (Production)","text":"<p>When running as a pod in Kubernetes:</p> <pre><code>apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: orca\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: orca-role\nrules:\n  - apiGroups: [\"\"]\n    resources: [\"nodes\", \"pods\", \"pods/status\"]\n    verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n  - apiGroups: [\"coordination.k8s.io\"]\n    resources: [\"leases\"]\n    verbs: [\"get\", \"create\", \"update\", \"patch\", \"delete\"]\n</code></pre> <p>ORCA automatically uses in-cluster config when <code>--kubeconfig</code> is not specified.</p>"},{"location":"architecture/virtual-kubelet/#2-kubeconfig-file-development","title":"2. Kubeconfig File (Development)","text":"<p>For local development:</p> <pre><code>orca --kubeconfig ~/.kube/config --config config.yaml\n</code></pre>"},{"location":"architecture/virtual-kubelet/#3-default-kubeconfig","title":"3. Default Kubeconfig","text":"<p>If no <code>--kubeconfig</code> specified and not in-cluster, ORCA tries <code>~/.kube/config</code>.</p>"},{"location":"architecture/virtual-kubelet/#node-heartbeat-lease","title":"Node Heartbeat &amp; Lease","text":"<p>ORCA maintains its node registration via Kubernetes leases:</p> <ul> <li>Lease Duration: 40 seconds</li> <li>Renew Interval: Automatic (handled by Virtual Kubelet)</li> <li>Namespace: Same as ORCA deployment (typically <code>kube-system</code>)</li> </ul> <p>If the lease expires (e.g., ORCA crashes), Kubernetes marks the node as <code>NotReady</code> and evicts pods.</p>"},{"location":"architecture/virtual-kubelet/#node-status-reporting","title":"Node Status Reporting","text":"<p>ORCA reports node conditions to Kubernetes:</p> <pre><code>node.Status.Conditions = []corev1.NodeCondition{\n    {\n        Type:   corev1.NodeReady,\n        Status: corev1.ConditionTrue,\n        Reason: \"OrcaProviderReady\",\n    },\n    {\n        Type:   corev1.NodeMemoryPressure,\n        Status: corev1.ConditionFalse,\n    },\n    // ... other conditions\n}\n</code></pre> <p>Node Info: <pre><code>node.Status.NodeInfo = corev1.NodeSystemInfo{\n    Architecture:            \"amd64\",\n    OperatingSystem:         \"Linux\",\n    KubeletVersion:          \"v1.0.0-orca\",\n    ContainerRuntimeVersion: \"orca://1.0.0\",\n    OSImage:                 \"AWS EC2\",\n}\n</code></pre></p>"},{"location":"architecture/virtual-kubelet/#logging","title":"Logging","text":"<p>ORCA uses structured logging (zerolog) throughout:</p> <pre><code># JSON format (production)\n{\"level\":\"info\",\"time\":\"2025-10-18T18:00:00Z\",\"message\":\"Starting ORCA Virtual Kubelet node\",\"node_name\":\"orca-aws-node\"}\n\n# Console format (development)\n2025-10-18T18:00:00Z INF Starting ORCA Virtual Kubelet node node_name=orca-aws-node\n</code></pre> <p>Log Levels: - <code>debug</code>: Detailed debugging information (AWS API calls, pod events) - <code>info</code>: General operational information (node registered, pods created) - <code>warn</code>: Warning conditions (spot instance interruption, quota limits) - <code>error</code>: Error conditions (instance launch failed, AWS API errors)</p> <p>Configure via config.yaml: <pre><code>logging:\n  level: info     # debug, info, warn, error\n  format: json    # json, text\n</code></pre></p>"},{"location":"architecture/virtual-kubelet/#error-handling","title":"Error Handling","text":"<p>ORCA handles errors at multiple levels:</p>"},{"location":"architecture/virtual-kubelet/#node-controller-errors","title":"Node Controller Errors","text":"<pre><code>// Startup errors (fatal - exit immediately)\nif err := controller.Run(ctx); err != nil {\n    logger.Fatal().Err(err).Msg(\"Controller error\")\n}\n\n// Runtime errors (logged, retry automatically)\nnode.WithNodeStatusUpdateErrorHandler(func(ctx context.Context, err error) error {\n    logger.Error().Err(err).Msg(\"Node status update failed\")\n    return err // Virtual Kubelet will retry\n})\n</code></pre>"},{"location":"architecture/virtual-kubelet/#pod-creation-errors","title":"Pod Creation Errors","text":"<pre><code>// Instance launch failure\nif err := awsClient.CreateInstance(ctx, pod, instanceType); err != nil {\n    // Update pod status to Failed\n    pod.Status.Phase = corev1.PodFailed\n    pod.Status.Conditions = append(pod.Status.Conditions, corev1.PodCondition{\n        Type:    corev1.PodReady,\n        Status:  corev1.ConditionFalse,\n        Reason:  \"InstanceCreationFailed\",\n        Message: fmt.Sprintf(\"Failed to create EC2 instance: %v\", err),\n    })\n    return err\n}\n</code></pre> <p>Common errors: - <code>InsufficientInstanceCapacity</code>: No capacity available (especially for GPU instances) - <code>InstanceLimitExceeded</code>: AWS account limits reached - <code>UnauthorizedOperation</code>: IAM permissions issue - <code>InvalidParameterValue</code>: Configuration error (bad AMI, subnet, etc.)</p>"},{"location":"architecture/virtual-kubelet/#testing","title":"Testing","text":""},{"location":"architecture/virtual-kubelet/#unit-tests","title":"Unit Tests","text":"<pre><code># Test Virtual Kubelet adapter\ngo test ./pkg/node/... -v\n\n# Test full integration\ngo test ./... -v\n</code></pre>"},{"location":"architecture/virtual-kubelet/#manual-testing","title":"Manual Testing","text":"<pre><code># 1. Start ORCA with local kubeconfig\n./orca --kubeconfig ~/.kube/config --config config.yaml --log-level debug\n\n# 2. Verify node registered\nkubectl get nodes\n# Should show: orca-aws-node   Ready   &lt;none&gt;   10s   v1.0.0-orca\n\n# 3. Deploy test pod\nkubectl apply -f examples/gpu-training-pod.yaml\n\n# 4. Watch pod status\nkubectl get pods -w\n\n# 5. Check ORCA logs\n# Should see: CreatePod called, instance launching, pod running\n\n# 6. Verify EC2 instance created\naws ec2 describe-instances --filters \"Name=tag:ManagedBy,Values=ORCA\"\n\n# 7. Delete pod\nkubectl delete pod gpu-training\n\n# 8. Verify instance terminated\naws ec2 describe-instances --instance-ids &lt;instance-id&gt;\n</code></pre>"},{"location":"architecture/virtual-kubelet/#troubleshooting","title":"Troubleshooting","text":""},{"location":"architecture/virtual-kubelet/#node-not-appearing","title":"Node Not Appearing","text":"<p>Symptoms: <code>kubectl get nodes</code> doesn't show orca-aws-node</p> <p>Causes: 1. ORCA not running 2. Kubeconfig not configured 3. RBAC permissions missing 4. Network connectivity issues</p> <p>Solution: <pre><code># Check ORCA logs\n./orca --kubeconfig ~/.kube/config --log-level debug\n\n# Verify RBAC\nkubectl auth can-i create nodes --as=system:serviceaccount:kube-system:orca\n\n# Test Kubernetes connectivity\nkubectl cluster-info\n</code></pre></p>"},{"location":"architecture/virtual-kubelet/#pods-stuck-in-pending","title":"Pods Stuck in Pending","text":"<p>Symptoms: Pod scheduled to orca-aws-node but stays Pending</p> <p>Causes: 1. Missing instance-type annotation 2. AWS credentials not configured 3. EC2 instance launch failure 4. Subnet/security group misconfiguration</p> <p>Solution: <pre><code># Check pod events\nkubectl describe pod &lt;pod-name&gt;\n\n# Check ORCA logs\n# Look for: \"Failed to create instance\" errors\n\n# Verify AWS credentials\nAWS_PROFILE=orca aws sts get-caller-identity\n\n# Test EC2 instance launch manually\nAWS_PROFILE=orca aws ec2 run-instances \\\n  --image-id ami-xxx \\\n  --instance-type t3.micro \\\n  --subnet-id subnet-xxx \\\n  --security-group-ids sg-xxx\n</code></pre></p>"},{"location":"architecture/virtual-kubelet/#pod-stuck-in-unknown-state","title":"Pod Stuck in Unknown State","text":"<p>Symptoms: Pod shows \"Unknown\" or \"NodeLost\" status</p> <p>Causes: 1. ORCA crashed or killed 2. Node lease expired 3. Kubernetes API connectivity lost</p> <p>Solution: <pre><code># Check if ORCA is running\nps aux | grep orca\n\n# Check node lease\nkubectl get lease -n kube-system orca-aws-node\n\n# Restart ORCA\n./orca --kubeconfig ~/.kube/config --config config.yaml\n</code></pre></p>"},{"location":"architecture/virtual-kubelet/#security-considerations","title":"Security Considerations","text":"<ol> <li>RBAC: ORCA requires permissions to create/update nodes, pods, and leases</li> <li>AWS Credentials: Use IRSA (IAM Roles for Service Accounts) in production</li> <li>Network Policy: Ensure ORCA can reach Kubernetes API server</li> <li>Pod Security: ORCA runs as non-root user (UID 65532) in container</li> </ol>"},{"location":"architecture/virtual-kubelet/#performance","title":"Performance","text":"<ul> <li>Node Registration: ~1-2 seconds</li> <li>Pod Creation: ~60-90 seconds (EC2 instance boot time)</li> <li>Pod Status Sync: Every 10 seconds (Virtual Kubelet default)</li> <li>Node Heartbeat: Every 40 seconds (lease renewal)</li> </ul>"},{"location":"architecture/virtual-kubelet/#limitations","title":"Limitations","text":"<ol> <li>Container Runtime: Pods run as full EC2 instances, not containers</li> <li>Cannot use Docker/containerd features</li> <li>No shared node resources</li> <li> <p>Higher overhead than container pods</p> </li> <li> <p>Exec/Logs: Not yet implemented</p> </li> <li><code>kubectl logs</code> returns \"not implemented\"</li> <li><code>kubectl exec</code> returns \"not implemented\"</li> <li> <p>Future: Will use CloudWatch Logs and SSM Session Manager</p> </li> <li> <p>Volume Mounts: Not yet implemented</p> </li> <li>EmptyDir, HostPath not supported</li> <li> <p>Future: Will support EBS volumes and EFS</p> </li> <li> <p>Networking: Simplified model</p> </li> <li>Each pod gets its own EC2 instance with public/private IP</li> <li>No pod-to-pod networking within node</li> <li>No CNI plugin integration</li> </ol>"},{"location":"architecture/virtual-kubelet/#future-enhancements","title":"Future Enhancements","text":"<ul> <li> CloudWatch Logs integration for container logs</li> <li> SSM Session Manager for kubectl exec</li> <li> EBS volume support</li> <li> EFS volume support</li> <li> Multi-container pod support (multiple processes on single instance)</li> <li> Init container support</li> <li> Ephemeral container support</li> <li> Resource metrics via CloudWatch</li> <li> Custom metrics API integration</li> </ul>"},{"location":"architecture/virtual-kubelet/#references","title":"References","text":"<ul> <li>Virtual Kubelet Documentation</li> <li>Virtual Kubelet GitHub</li> <li>Kubernetes Node Documentation</li> <li>Kubernetes Pod Lifecycle</li> </ul>"},{"location":"community/","title":"Community","text":"<p>Join the ORCA community.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"community/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"community/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"community/license/","title":"License","text":"<p>ORCA's Apache 2.0 license.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"community/license/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"community/license/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"community/roadmap/","title":"Roadmap","text":"<p>ORCA's development roadmap and future plans.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"community/roadmap/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"community/roadmap/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"community/support/","title":"Support","text":"<p>How to get help with ORCA.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"community/support/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"community/support/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"development/","title":"Development Guide","text":"<p>Guide for contributing to ORCA development.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"development/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"development/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"development/building/","title":"Building ORCA","text":"<p>How to build ORCA from source.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"development/building/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"development/building/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"development/code-style/","title":"Code Style","text":"<p>Coding standards and style guide for ORCA.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"development/code-style/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"development/code-style/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"development/contributing/","title":"Contributing","text":"<p>How to contribute to ORCA.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"development/contributing/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"development/contributing/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"development/localstack/","title":"LocalStack Testing Guide","text":"<p>This guide explains how to use LocalStack for local development and testing of ORCA without incurring AWS costs.</p>"},{"location":"development/localstack/#overview","title":"Overview","text":"<p>LocalStack is a fully functional local AWS cloud stack that emulates AWS services on your local machine. This allows you to:</p> <ul> <li>Develop and test AWS integrations without AWS costs</li> <li>Test faster (no internet latency)</li> <li>Test in isolation (no conflicts with production resources)</li> <li>Run integration tests in CI/CD pipelines</li> </ul>"},{"location":"development/localstack/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker and Docker Compose installed</li> <li>AWS CLI installed (for awslocal commands)</li> <li>Python 3 and pip3 (for awslocal wrapper)</li> </ul>"},{"location":"development/localstack/#installing-awslocal","title":"Installing awslocal","text":"<p>The <code>awslocal</code> CLI is a wrapper around the AWS CLI that automatically configures it to use LocalStack:</p> <pre><code>pip3 install awscli-local\n</code></pre> <p>Alternatively, you can use the regular AWS CLI with LocalStack by setting environment variables:</p> <pre><code>export AWS_ACCESS_KEY_ID=test\nexport AWS_SECRET_ACCESS_KEY=test\nexport AWS_DEFAULT_REGION=us-west-2\nexport AWS_ENDPOINT_URL=http://localhost:4566\n</code></pre>"},{"location":"development/localstack/#quick-start","title":"Quick Start","text":""},{"location":"development/localstack/#1-start-localstack","title":"1. Start LocalStack","text":"<pre><code>make localstack-start\n</code></pre> <p>This will: - Start LocalStack in a Docker container - Expose the LocalStack gateway on port 4566 - Automatically run initialization scripts to create test resources - Store data in <code>/tmp/localstack</code> for persistence</p>"},{"location":"development/localstack/#2-check-initialization-status","title":"2. Check Initialization Status","text":"<pre><code># View LocalStack logs\nmake localstack-logs\n\n# Check resource IDs\nmake localstack-status\n</code></pre> <p>The initialization script creates: - VPC with DNS support - Internet Gateway - Public subnet in us-west-2a - Route table with internet access - Security group with SSH access - Test AMI for launching instances</p>"},{"location":"development/localstack/#3-verify-localstack-is-ready","title":"3. Verify LocalStack is Ready","text":"<pre><code>./scripts/wait-for-localstack.sh\n</code></pre>"},{"location":"development/localstack/#4-run-tests","title":"4. Run Tests","text":"<pre><code># Run integration tests\nmake test-integration\n\n# Or run all tests\nmake test\n</code></pre>"},{"location":"development/localstack/#5-run-orca-locally","title":"5. Run ORCA Locally","text":"<pre><code>make run-local\n</code></pre> <p>This starts ORCA with the LocalStack configuration (<code>config.localstack.yaml</code>).</p>"},{"location":"development/localstack/#6-stop-localstack","title":"6. Stop LocalStack","text":"<pre><code>make localstack-stop\n</code></pre>"},{"location":"development/localstack/#configuration","title":"Configuration","text":""},{"location":"development/localstack/#localstack-configuration","title":"LocalStack Configuration","text":"<p>The LocalStack environment is configured in <code>docker-compose.localstack.yml</code>:</p> <ul> <li>Services: EC2, IAM, STS, CloudWatch, CloudWatch Logs</li> <li>Endpoint: http://localhost:4566</li> <li>Persistence: Enabled (data survives container restarts)</li> <li>VM Manager: Docker (for EC2 instances)</li> </ul>"},{"location":"development/localstack/#orca-configuration","title":"ORCA Configuration","text":"<p>ORCA uses <code>config.localstack.yaml</code> for LocalStack testing:</p> <pre><code>aws:\n  region: us-west-2\n  localStackEndpoint: http://localhost:4566\n  credentials:\n    accessKeyID: test\n    secretAccessKey: test\n  # ... other settings\n</code></pre>"},{"location":"development/localstack/#working-with-localstack","title":"Working with LocalStack","text":""},{"location":"development/localstack/#querying-resources","title":"Querying Resources","text":"<pre><code># List EC2 instances\nawslocal ec2 describe-instances --region us-west-2\n\n# List VPCs\nawslocal ec2 describe-vpcs --region us-west-2\n\n# List security groups\nawslocal ec2 describe-security-groups --region us-west-2\n\n# List subnets\nawslocal ec2 describe-subnets --region us-west-2\n</code></pre>"},{"location":"development/localstack/#launching-test-instances","title":"Launching Test Instances","text":"<pre><code># Get resource IDs from initialization\nsource /tmp/localstack-orca-resources.env\n\n# Launch an instance\nawslocal ec2 run-instances \\\n  --image-id $LOCALSTACK_AMI_ID \\\n  --instance-type t3.medium \\\n  --subnet-id $LOCALSTACK_SUBNET_ID \\\n  --security-group-ids $LOCALSTACK_SG_ID \\\n  --tag-specifications 'ResourceType=instance,Tags=[{Key=Name,Value=test-instance}]'\n</code></pre>"},{"location":"development/localstack/#viewing-logs","title":"Viewing Logs","text":"<pre><code># Follow all LocalStack logs\nmake localstack-logs\n\n# View specific service logs\ndocker exec orca-localstack cat /var/log/localstack/ec2.log\n</code></pre>"},{"location":"development/localstack/#opening-a-shell-in-localstack","title":"Opening a Shell in LocalStack","text":"<pre><code>make localstack-shell\n</code></pre>"},{"location":"development/localstack/#testing-workflow","title":"Testing Workflow","text":""},{"location":"development/localstack/#unit-tests","title":"Unit Tests","text":"<p>Unit tests don't require LocalStack and use mocks:</p> <pre><code>make test\n</code></pre>"},{"location":"development/localstack/#integration-tests","title":"Integration Tests","text":"<p>Integration tests connect to LocalStack and test real AWS SDK interactions:</p> <pre><code># Start LocalStack\nmake localstack-start\n\n# Wait for it to be ready\n./scripts/wait-for-localstack.sh\n\n# Run integration tests\nmake test-integration\n\n# Stop LocalStack when done\nmake localstack-stop\n</code></pre>"},{"location":"development/localstack/#testing-orca-end-to-end","title":"Testing ORCA End-to-End","text":"<pre><code># 1. Start LocalStack\nmake localstack-start\n\n# 2. Build ORCA\nmake build\n\n# 3. Run ORCA with LocalStack config\nmake run-local\n\n# 4. In another terminal, deploy a test pod\nkubectl apply -f examples/test-pod.yaml\n\n# 5. Check ORCA logs to see instance creation\n# 6. Verify instance in LocalStack\nawslocal ec2 describe-instances\n\n# 7. Stop ORCA (Ctrl+C)\n# 8. Stop LocalStack\nmake localstack-stop\n</code></pre>"},{"location":"development/localstack/#makefile-targets","title":"Makefile Targets","text":"Target Description <code>make localstack-start</code> Start LocalStack container <code>make localstack-stop</code> Stop LocalStack container <code>make localstack-restart</code> Restart LocalStack <code>make localstack-logs</code> Follow LocalStack logs <code>make localstack-status</code> Show created resource IDs <code>make localstack-shell</code> Open bash in LocalStack container <code>make test-integration</code> Run integration tests <code>make run-local</code> Run ORCA with LocalStack config"},{"location":"development/localstack/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/localstack/#localstack-wont-start","title":"LocalStack Won't Start","text":"<pre><code># Check if port 4566 is already in use\nlsof -i :4566\n\n# Check Docker status\ndocker ps -a | grep localstack\n\n# View container logs\ndocker logs orca-localstack\n\n# Remove and restart\nmake localstack-stop\ndocker rm -f orca-localstack\nmake localstack-start\n</code></pre>"},{"location":"development/localstack/#resources-not-initialized","title":"Resources Not Initialized","text":"<pre><code># Check initialization logs\nmake localstack-logs | grep -A 20 \"Initializing LocalStack\"\n\n# Resource IDs are saved here\ncat /tmp/localstack-orca-resources.env\n\n# Re-run initialization manually\ndocker exec orca-localstack /docker-entrypoint-initaws.d/01-init-ec2.sh\n</code></pre>"},{"location":"development/localstack/#tests-fail-with-connection-errors","title":"Tests Fail with Connection Errors","text":"<pre><code># Verify LocalStack is running\ndocker ps | grep localstack\n\n# Check LocalStack health\ncurl http://localhost:4566/_localstack/health\n\n# Verify EC2 service is available\nawslocal ec2 describe-regions --region us-west-2\n\n# Wait for LocalStack to be fully ready\n./scripts/wait-for-localstack.sh\n</code></pre>"},{"location":"development/localstack/#ec2-instances-dont-start","title":"EC2 Instances Don't Start","text":"<p>LocalStack uses Docker-in-Docker for EC2 instances. Ensure:</p> <pre><code># Docker socket is mounted (in docker-compose.localstack.yml)\nvolumes:\n  - \"/var/run/docker.sock:/var/run/docker.sock\"\n\n# Check LocalStack EC2 logs\ndocker exec orca-localstack cat /var/log/localstack/ec2.log\n</code></pre> <p>Note: LocalStack's EC2 emulation has limitations compared to real AWS: - Instance types are simulated (no real resource limits) - Networking is simplified - Some advanced EC2 features may not work</p>"},{"location":"development/localstack/#clear-all-localstack-data","title":"Clear All LocalStack Data","text":"<pre><code># Stop LocalStack\nmake localstack-stop\n\n# Clear persistent data\nrm -rf /tmp/localstack/*\n\n# Clear resource IDs\nrm -f /tmp/localstack-orca-resources.env\n\n# Restart fresh\nmake localstack-start\n</code></pre>"},{"location":"development/localstack/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"development/localstack/#github-actions-example","title":"GitHub Actions Example","text":"<pre><code>name: Integration Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Set up Go\n        uses: actions/setup-go@v4\n        with:\n          go-version: '1.23'\n\n      - name: Start LocalStack\n        run: make localstack-start\n\n      - name: Wait for LocalStack\n        run: ./scripts/wait-for-localstack.sh\n\n      - name: Run Integration Tests\n        run: make test-integration\n\n      - name: Stop LocalStack\n        if: always()\n        run: make localstack-stop\n</code></pre>"},{"location":"development/localstack/#differences-from-real-aws","title":"Differences from Real AWS","text":"<p>Be aware of these differences when using LocalStack:</p>"},{"location":"development/localstack/#supported-features","title":"Supported Features","text":"<ul> <li>\u2705 EC2 instance launch/terminate</li> <li>\u2705 VPC, subnets, security groups</li> <li>\u2705 Tags and resource filtering</li> <li>\u2705 IAM roles and policies (basic)</li> <li>\u2705 CloudWatch Logs</li> <li>\u2705 Basic networking</li> </ul>"},{"location":"development/localstack/#limitedunsupported-features","title":"Limited/Unsupported Features","text":"<ul> <li>\u274c Spot instance pricing (spot launches work, but no real pricing)</li> <li>\u274c Capacity Reservations</li> <li>\u274c Real instance resource limits</li> <li>\u274c Some advanced networking features</li> <li>\u274c AWS-specific instance metadata</li> <li>\u274c Real GPU support</li> </ul>"},{"location":"development/localstack/#testing-strategy","title":"Testing Strategy","text":"<p>Use LocalStack for: - Unit-level integration tests: Testing AWS SDK calls - Logic validation: Testing tag application, instance selection - Error handling: Testing timeout, failure scenarios - Development: Fast iteration without AWS costs</p> <p>Use real AWS for: - End-to-end testing: Full production-like validation - Performance testing: Real instance performance - Advanced features: Capacity Reservations, Spot, GPUs - Pre-production validation: Final testing before release</p>"},{"location":"development/localstack/#best-practices","title":"Best Practices","text":"<ol> <li>Always wait for initialization: Use <code>./scripts/wait-for-localstack.sh</code></li> <li>Use resource IDs from env file: Source <code>/tmp/localstack-orca-resources.env</code></li> <li>Check logs frequently: LocalStack logs reveal issues quickly</li> <li>Clear data between test runs: Ensure clean state</li> <li>Don't rely on persistence for CI: Treat as ephemeral</li> <li>Test failures locally first: LocalStack makes debugging easier</li> <li>Validate against real AWS: LocalStack is a simulation</li> </ol>"},{"location":"development/localstack/#additional-resources","title":"Additional Resources","text":"<ul> <li>LocalStack Documentation</li> <li>LocalStack AWS Service Coverage</li> <li>awslocal CLI Reference</li> <li>LocalStack GitHub</li> </ul>"},{"location":"development/localstack/#getting-help","title":"Getting Help","text":"<p>If you encounter issues with LocalStack:</p> <ol> <li>Check LocalStack logs: <code>make localstack-logs</code></li> <li>Verify health: <code>curl http://localhost:4566/_localstack/health</code></li> <li>Check GitHub issues: https://github.com/localstack/localstack/issues</li> <li>LocalStack Community: https://discuss.localstack.cloud/</li> </ol>"},{"location":"development/setup/","title":"ORCA Development Guide","text":"<p>This guide covers local development setup, testing, and contribution workflows for ORCA.</p>"},{"location":"development/setup/#prerequisites","title":"Prerequisites","text":""},{"location":"development/setup/#required-tools","title":"Required Tools","text":"<ul> <li>Go 1.21+ - Install Go</li> <li>Docker - Install Docker</li> <li>kubectl - Install kubectl</li> <li>kind (optional) - For local Kubernetes testing</li> <li>golangci-lint - For code linting</li> </ul>"},{"location":"development/setup/#install-development-tools","title":"Install Development Tools","text":"<pre><code># Install golangci-lint\ngo install github.com/golangci/golangci-lint/cmd/golangci-lint@latest\n\n# Install kind (Kubernetes in Docker) - optional\ngo install sigs.k8s.io/kind@latest\n</code></pre>"},{"location":"development/setup/#getting-started","title":"Getting Started","text":""},{"location":"development/setup/#1-clone-and-setup","title":"1. Clone and Setup","text":"<pre><code># Clone the repository\ngit clone https://github.com/scttfrdmn/orca.git\ncd orca\n\n# Download dependencies\nmake mod-download\n\n# Verify setup\nmake test\n</code></pre>"},{"location":"development/setup/#2-project-structure","title":"2. Project Structure","text":"<pre><code>orca/\n\u251c\u2500\u2500 cmd/orca/              # Main application entry point\n\u251c\u2500\u2500 pkg/                   # Public packages\n\u2502   \u251c\u2500\u2500 provider/          # Virtual Kubelet provider\n\u2502   \u251c\u2500\u2500 config/            # Configuration management\n\u2502   \u2514\u2500\u2500 instances/         # Instance selection logic\n\u251c\u2500\u2500 internal/              # Private packages\n\u2502   \u251c\u2500\u2500 aws/               # AWS SDK integration\n\u2502   \u251c\u2500\u2500 container/         # Container runtime\n\u2502   \u2514\u2500\u2500 metrics/           # Metrics and monitoring\n\u251c\u2500\u2500 docs/                  # Documentation\n\u251c\u2500\u2500 deploy/                # Deployment manifests\n\u251c\u2500\u2500 examples/              # User examples\n\u2514\u2500\u2500 scripts/               # Utility scripts\n</code></pre>"},{"location":"development/setup/#development-workflow","title":"Development Workflow","text":""},{"location":"development/setup/#building","title":"Building","text":"<pre><code># Build the binary\nmake build\n\n# Output: bin/orca\n</code></pre>"},{"location":"development/setup/#testing","title":"Testing","text":"<pre><code># Run all tests\nmake test\n\n# Run tests with coverage\nmake coverage\n\n# Run tests for specific package\ngo test -v ./pkg/provider/...\n</code></pre>"},{"location":"development/setup/#code-quality","title":"Code Quality","text":"<pre><code># Format code\nmake fmt\n\n# Run linter\nmake lint\n\n# Run go vet\nmake vet\n\n# Run all quality checks\nmake fmt &amp;&amp; make lint &amp;&amp; make vet &amp;&amp; make test\n</code></pre>"},{"location":"development/setup/#running-locally","title":"Running Locally","text":"<pre><code># Create a config file\ncat &gt; config.yaml &lt;&lt;EOF\naws:\n  region: us-west-2\n  credentials:\n    accessKeyID: AKIA...\n    secretAccessKey: your-secret-key\n\nnode:\n  name: orca-dev-node\n  operatingSystem: Linux\n  cpu: 1000\n  memory: 1Ti\n  pods: 1000\n\nlogging:\n  level: debug\nEOF\n\n# Run ORCA\nmake run\n\n# Or run directly\n./bin/orca --config config.yaml --kubeconfig ~/.kube/config\n</code></pre>"},{"location":"development/setup/#testing-with-local-kubernetes","title":"Testing with Local Kubernetes","text":""},{"location":"development/setup/#setup-kind-cluster","title":"Setup kind Cluster","text":"<pre><code># Create a kind cluster\nkind create cluster --name orca-dev\n\n# Verify\nkubectl cluster-info --context kind-orca-dev\n</code></pre>"},{"location":"development/setup/#deploy-orca-to-kind","title":"Deploy ORCA to kind","text":"<pre><code># Build Docker image\nmake docker-build\n\n# Load image into kind\nkind load docker-image orca:latest --name orca-dev\n\n# Deploy\nkubectl apply -f deploy/kubernetes/\n\n# Verify\nkubectl get pods -n kube-system | grep orca\n</code></pre>"},{"location":"development/setup/#test-pod-creation","title":"Test Pod Creation","text":"<pre><code># Create a test pod\ncat &lt;&lt;EOF | kubectl apply -f -\napiVersion: v1\nkind: Pod\nmetadata:\n  name: test-burst-pod\n  annotations:\n    orca.research/instance-type: \"t3.small\"\nspec:\n  nodeSelector:\n    orca.research/provider: \"aws\"\n  tolerations:\n  - key: orca.research/burst-node\n    operator: Equal\n    value: \"true\"\n    effect: NoSchedule\n  containers:\n  - name: test\n    image: busybox\n    command: [\"sleep\", \"3600\"]\nEOF\n\n# Check pod status\nkubectl get pod test-burst-pod -o wide\n\n# Check ORCA logs\nkubectl logs -n kube-system -l app=orca\n</code></pre>"},{"location":"development/setup/#aws-configuration","title":"AWS Configuration","text":""},{"location":"development/setup/#using-aws-cli-credentials","title":"Using AWS CLI Credentials","text":"<pre><code># Configure AWS CLI\naws configure\n\n# ORCA will use ~/.aws/credentials automatically\n</code></pre>"},{"location":"development/setup/#using-iam-role-recommended-for-production","title":"Using IAM Role (Recommended for Production)","text":"<pre><code># config.yaml\naws:\n  region: us-west-2\n  # No credentials needed - uses IAM role\n</code></pre>"},{"location":"development/setup/#required-iam-permissions","title":"Required IAM Permissions","text":"<pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"ec2:RunInstances\",\n        \"ec2:TerminateInstances\",\n        \"ec2:DescribeInstances\",\n        \"ec2:DescribeInstanceTypes\",\n        \"ec2:CreateTags\",\n        \"ec2:DescribeTags\"\n      ],\n      \"Resource\": \"*\"\n    }\n  ]\n}\n</code></pre>"},{"location":"development/setup/#debugging","title":"Debugging","text":""},{"location":"development/setup/#enable-debug-logging","title":"Enable Debug Logging","text":"<pre><code># Via config file\ncat &gt; config.yaml &lt;&lt;EOF\nlogging:\n  level: debug\nEOF\n\n# Via command line\n./bin/orca --log-level=debug\n</code></pre>"},{"location":"development/setup/#common-issues","title":"Common Issues","text":""},{"location":"development/setup/#issue-cannot-connect-to-kubernetes-cluster","title":"Issue: Cannot connect to Kubernetes cluster","text":"<pre><code># Verify kubeconfig\nkubectl cluster-info\n\n# Specify kubeconfig explicitly\n./bin/orca --kubeconfig ~/.kube/config\n</code></pre>"},{"location":"development/setup/#issue-aws-credentials-not-found","title":"Issue: AWS credentials not found","text":"<pre><code># Verify AWS credentials\naws sts get-caller-identity\n\n# Set credentials explicitly in config.yaml\n</code></pre>"},{"location":"development/setup/#issue-pod-stuck-in-pending-state","title":"Issue: Pod stuck in Pending state","text":"<pre><code># Check pod events\nkubectl describe pod &lt;pod-name&gt;\n\n# Check ORCA logs\nkubectl logs -n kube-system -l app=orca\n\n# Check AWS instance creation\naws ec2 describe-instances --filters \"Name=tag:orca.research/pod,Values=&lt;pod-name&gt;\"\n</code></pre>"},{"location":"development/setup/#architecture-patterns","title":"Architecture Patterns","text":""},{"location":"development/setup/#provider-interface","title":"Provider Interface","text":"<pre><code>// pkg/provider/provider.go\n\ntype Provider interface {\n    // Pod lifecycle\n    CreatePod(ctx context.Context, pod *corev1.Pod) error\n    UpdatePod(ctx context.Context, pod *corev1.Pod) error\n    DeletePod(ctx context.Context, pod *corev1.Pod) error\n    GetPod(ctx context.Context, namespace, name string) (*corev1.Pod, error)\n    GetPodStatus(ctx context.Context, namespace, name string) (*corev1.PodStatus, error)\n    GetPods(ctx context.Context) ([]*corev1.Pod, error)\n}\n</code></pre>"},{"location":"development/setup/#instance-selection","title":"Instance Selection","text":"<pre><code>// pkg/instances/selector.go\n\n// Selector chooses the appropriate EC2 instance type\ntype Selector interface {\n    // Select returns instance type for pod\n    Select(pod *corev1.Pod) (string, error)\n}\n\n// Three selection strategies\ntype ExplicitSelector struct{}  // Priority 1: User-specified\ntype TemplateSelector struct{}  // Priority 2: Named templates\ntype AutoSelector struct{}      // Priority 3: Auto-selection\n</code></pre>"},{"location":"development/setup/#configuration-management","title":"Configuration Management","text":"<pre><code>// pkg/config/config.go\n\ntype Config struct {\n    AWS       AWSConfig       `yaml:\"aws\"`\n    Node      NodeConfig      `yaml:\"node\"`\n    Instances InstancesConfig `yaml:\"instances\"`\n    Logging   LoggingConfig   `yaml:\"logging\"`\n}\n</code></pre>"},{"location":"development/setup/#writing-tests","title":"Writing Tests","text":""},{"location":"development/setup/#unit-test-example","title":"Unit Test Example","text":"<pre><code>// pkg/instances/selector_test.go\n\nfunc TestExplicitSelector(t *testing.T) {\n    tests := []struct {\n        name        string\n        annotations map[string]string\n        expected    string\n        expectError bool\n    }{\n        {\n            name: \"explicit p5.48xlarge\",\n            annotations: map[string]string{\n                \"orca.research/instance-type\": \"p5.48xlarge\",\n            },\n            expected:    \"p5.48xlarge\",\n            expectError: false,\n        },\n        {\n            name:        \"no annotation\",\n            annotations: map[string]string{},\n            expected:    \"\",\n            expectError: true,\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            pod := &amp;corev1.Pod{\n                ObjectMeta: metav1.ObjectMeta{\n                    Annotations: tt.annotations,\n                },\n            }\n\n            selector := NewExplicitSelector()\n            result, err := selector.Select(pod)\n\n            if tt.expectError &amp;&amp; err == nil {\n                t.Error(\"expected error, got nil\")\n            }\n            if !tt.expectError &amp;&amp; err != nil {\n                t.Errorf(\"unexpected error: %v\", err)\n            }\n            if result != tt.expected {\n                t.Errorf(\"expected %s, got %s\", tt.expected, result)\n            }\n        })\n    }\n}\n</code></pre>"},{"location":"development/setup/#integration-test-example","title":"Integration Test Example","text":"<pre><code>// internal/aws/client_test.go\n\n// +build integration\n\nfunc TestCreateInstance(t *testing.T) {\n    if testing.Short() {\n        t.Skip(\"skipping integration test\")\n    }\n\n    // Setup\n    client := NewClient(/* config */)\n    pod := createTestPod()\n\n    // Execute\n    err := client.CreateInstance(context.Background(), pod)\n    if err != nil {\n        t.Fatalf(\"failed to create instance: %v\", err)\n    }\n\n    // Verify\n    instances, err := client.DescribeInstances(context.Background(), pod)\n    if err != nil || len(instances) != 1 {\n        t.Errorf(\"expected 1 instance, got %d\", len(instances))\n    }\n\n    // Cleanup\n    defer client.TerminateInstance(context.Background(), instances[0].ID)\n}\n</code></pre>"},{"location":"development/setup/#performance-profiling","title":"Performance Profiling","text":""},{"location":"development/setup/#cpu-profiling","title":"CPU Profiling","text":"<pre><code># Build with profiling\ngo build -o bin/orca ./cmd/orca\n\n# Run with CPU profiling\n./bin/orca --cpuprofile=cpu.prof\n\n# Analyze profile\ngo tool pprof cpu.prof\n</code></pre>"},{"location":"development/setup/#memory-profiling","title":"Memory Profiling","text":"<pre><code># Run with memory profiling\n./bin/orca --memprofile=mem.prof\n\n# Analyze profile\ngo tool pprof mem.prof\n</code></pre>"},{"location":"development/setup/#release-process","title":"Release Process","text":""},{"location":"development/setup/#version-bump","title":"Version Bump","text":"<pre><code># Update VERSION file\necho \"0.2.0\" &gt; VERSION\n\n# Update CHANGELOG.md\n# Move [Unreleased] items to [0.2.0] section\n\n# Commit\ngit add VERSION CHANGELOG.md\ngit commit -m \"chore: bump version to 0.2.0\"\n\n# Tag\ngit tag -a v0.2.0 -m \"Release v0.2.0\"\ngit push origin v0.2.0\n</code></pre>"},{"location":"development/setup/#getting-help","title":"Getting Help","text":"<ul> <li>GitHub Issues - Report bugs or request features</li> <li>GitHub Discussions - Ask questions</li> <li>Research Partners - Contact NRP, SDSU teams</li> </ul>"},{"location":"development/setup/#additional-resources","title":"Additional Resources","text":"<ul> <li>Virtual Kubelet Documentation</li> <li>AWS SDK for Go v2</li> <li>Kubernetes Client Go</li> <li>Effective Go</li> </ul>"},{"location":"development/testing/","title":"ORCA Testing Guide","text":"<p>This document describes ORCA's testing approach: pragmatic, functional, and value-driven. Every test serves a clear purpose - catching real bugs, preventing regressions, or improving development speed.</p>"},{"location":"development/testing/#testing-philosophy","title":"Testing Philosophy","text":"<p>No testing for testing's sake. Every test must provide: 1. Bug prevention - Catches real issues before production 2. Regression protection - Prevents broken code from merging 3. Development velocity - Makes refactoring safe and fast 4. Documentation - Shows how code should work</p> <p>If a test doesn't provide clear value, we don't write it.</p>"},{"location":"development/testing/#test-types","title":"Test Types","text":""},{"location":"development/testing/#1-lint-code-quality","title":"1. Lint (Code Quality)","text":"<p>Purpose: Catch common mistakes and enforce consistency When: Pre-commit, CI on every PR Value: Prevents bugs, ensures idiomatic Go code</p> <pre><code># Run linters\nmake lint\n\n# Auto-fix issues\ngolangci-lint run --fix\n</code></pre> <p>What we check: - \u2705 <code>go vet</code> - Suspicious constructs - \u2705 <code>staticcheck</code> - Go best practices - \u2705 <code>errcheck</code> - Unchecked errors - \u2705 <code>gosec</code> - Security issues - \u2705 <code>gofmt</code> - Code formatting - \u2705 <code>gocritic</code> - Style issues</p> <p>Example catches: <pre><code>// BAD: Uncaught error\nec2Client.TerminateInstance(instanceID)\n\n// GOOD: Error handling\nif err := ec2Client.TerminateInstance(instanceID); err != nil {\n    return fmt.Errorf(\"failed to terminate: %w\", err)\n}\n</code></pre></p>"},{"location":"development/testing/#2-unit-tests-fast-feedback","title":"2. Unit Tests (Fast Feedback)","text":"<p>Purpose: Test individual functions in isolation When: TDD during development, CI on every PR Value: Fast feedback, safe refactoring, clear API contracts</p> <pre><code># Run unit tests\nmake test\n\n# Run specific package\ngo test -v ./pkg/instances/...\n\n# Run specific test\ngo test -v ./pkg/instances -run TestExplicitSelector\n</code></pre> <p>What to unit test: - \u2705 Instance selection logic - Core functionality - \u2705 Configuration parsing - Prevents config bugs - \u2705 Pod annotation extraction - Common bug source - \u2705 Budget calculations - Critical for cost control - \u2705 Tag generation - Required for pod tracking - \u2705 Error handling - Ensures graceful failures</p> <p>What NOT to unit test: - \u274c Trivial getters/setters - \u274c Third-party library behavior - \u274c Code that's just wiring</p>"},{"location":"development/testing/#example-instance-selector","title":"Example: Instance Selector","text":"<pre><code>// pkg/instances/selector_test.go\n\nfunc TestExplicitSelector(t *testing.T) {\n    tests := []struct {\n        name        string\n        pod         *corev1.Pod\n        expected    string\n        expectError bool\n    }{\n        {\n            name: \"explicit p5.48xlarge annotation\",\n            pod: &amp;corev1.Pod{\n                ObjectMeta: metav1.ObjectMeta{\n                    Annotations: map[string]string{\n                        AnnotationInstanceType: \"p5.48xlarge\",\n                    },\n                },\n            },\n            expected:    \"p5.48xlarge\",\n            expectError: false,\n        },\n        {\n            name: \"missing annotation returns error\",\n            pod: &amp;corev1.Pod{\n                ObjectMeta: metav1.ObjectMeta{\n                    Annotations: map[string]string{},\n                },\n            },\n            expected:    \"\",\n            expectError: true,\n        },\n        {\n            name: \"invalid instance type returns error\",\n            pod: &amp;corev1.Pod{\n                ObjectMeta: metav1.ObjectMeta{\n                    Annotations: map[string]string{\n                        AnnotationInstanceType: \"invalid-type\",\n                    },\n                },\n            },\n            expected:    \"\",\n            expectError: true,\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            selector := NewExplicitSelector()\n            result, err := selector.Select(tt.pod)\n\n            if tt.expectError &amp;&amp; err == nil {\n                t.Error(\"expected error but got nil\")\n            }\n            if !tt.expectError &amp;&amp; err != nil {\n                t.Errorf(\"unexpected error: %v\", err)\n            }\n            if result != tt.expected {\n                t.Errorf(\"expected %s, got %s\", tt.expected, result)\n            }\n        })\n    }\n}\n</code></pre> <p>Value: This test catches 90% of selector bugs in milliseconds.</p>"},{"location":"development/testing/#example-budget-enforcement","title":"Example: Budget Enforcement","text":"<pre><code>// pkg/budget/enforcer_test.go\n\nfunc TestBudgetEnforcement(t *testing.T) {\n    tests := []struct {\n        name           string\n        dailyBudget    float64\n        currentSpend   float64\n        instanceCost   float64\n        shouldAllow    bool\n    }{\n        {\n            name:         \"under budget allows instance\",\n            dailyBudget:  50.00,\n            currentSpend: 10.00,\n            instanceCost: 5.00,\n            shouldAllow:  true,\n        },\n        {\n            name:         \"at budget limit denies instance\",\n            dailyBudget:  50.00,\n            currentSpend: 48.00,\n            instanceCost: 5.00,\n            shouldAllow:  false,\n        },\n        {\n            name:         \"zero budget denies all\",\n            dailyBudget:  0.00,\n            currentSpend: 0.00,\n            instanceCost: 0.01,\n            shouldAllow:  false,\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            enforcer := &amp;BudgetEnforcer{\n                DailyLimit:   tt.dailyBudget,\n                CurrentSpend: tt.currentSpend,\n            }\n\n            allowed := enforcer.CanLaunchInstance(tt.instanceCost)\n\n            if allowed != tt.shouldAllow {\n                t.Errorf(\"expected %v, got %v\", tt.shouldAllow, allowed)\n            }\n        })\n    }\n}\n</code></pre> <p>Value: Prevents cost overruns - critical for production.</p>"},{"location":"development/testing/#3-integration-tests-real-interactions","title":"3. Integration Tests (Real Interactions)","text":"<p>Purpose: Test components working together When: After unit tests pass, CI on merge to main Value: Catches integration bugs, validates AWS interactions</p> <pre><code># Run integration tests (requires AWS credentials)\nmake integration-test\n\n# Or run with specific tag\ngo test -v -tags=integration ./...\n</code></pre> <p>What to integration test: - \u2705 AWS SDK calls - Ensure EC2 APIs work - \u2705 Kubernetes API - Verify pod operations - \u2705 Instance lifecycle - Create \u2192 Run \u2192 Terminate - \u2705 Configuration loading - Test full config chain - \u2705 Error scenarios - Network failures, AWS throttling</p>"},{"location":"development/testing/#example-aws-client-integration","title":"Example: AWS Client Integration","text":"<pre><code>// internal/aws/client_test.go\n// +build integration\n\nfunc TestEC2CreateInstance(t *testing.T) {\n    if testing.Short() {\n        t.Skip(\"skipping integration test\")\n    }\n\n    // Setup\n    cfg := loadTestConfig(t)\n    client := NewClient(cfg)\n\n    pod := &amp;corev1.Pod{\n        ObjectMeta: metav1.ObjectMeta{\n            Name:      \"test-pod\",\n            Namespace: \"default\",\n            Annotations: map[string]string{\n                AnnotationInstanceType: \"t3.small\",\n            },\n        },\n        Spec: corev1.PodSpec{\n            Containers: []corev1.Container{\n                {\n                    Name:  \"test\",\n                    Image: \"busybox\",\n                },\n            },\n        },\n    }\n\n    // Execute\n    ctx := context.Background()\n    instanceID, err := client.CreateInstance(ctx, pod)\n    if err != nil {\n        t.Fatalf(\"failed to create instance: %v\", err)\n    }\n\n    // Verify\n    instance, err := client.DescribeInstance(ctx, instanceID)\n    if err != nil {\n        t.Fatalf(\"failed to describe instance: %v\", err)\n    }\n    if instance.State != \"running\" &amp;&amp; instance.State != \"pending\" {\n        t.Errorf(\"expected running/pending, got %s\", instance.State)\n    }\n\n    // Cleanup\n    defer func() {\n        if err := client.TerminateInstance(ctx, instanceID); err != nil {\n            t.Errorf(\"cleanup failed: %v\", err)\n        }\n    }()\n}\n</code></pre> <p>Value: Catches AWS API changes, permission issues, network problems.</p> <p>Cost control for integration tests: <pre><code>// Use smallest instance types\nconst testInstanceType = \"t3.nano\"  // $0.0052/hour\n\n// Set short timeouts\nctx, cancel := context.WithTimeout(context.Background(), 2*time.Minute)\ndefer cancel()\n\n// Always cleanup\ndefer cleanupTestResources(t, client)\n</code></pre></p>"},{"location":"development/testing/#4-smoke-tests-quick-sanity-check","title":"4. Smoke Tests (Quick Sanity Check)","text":"<p>Purpose: Verify basic functionality works end-to-end When: After deployment, before releasing Value: Catches deployment issues, validates basic workflows</p> <pre><code># Run smoke tests against deployed ORCA\nmake smoke-test CLUSTER=kind-orca-dev\n\n# Or manually\n./scripts/smoke-test.sh\n</code></pre> <p>What smoke tests check: - \u2705 ORCA pod is running - \u2705 Virtual node is registered - \u2705 Simple pod can be created - \u2705 Instance launches successfully - \u2705 Pod reaches Running state - \u2705 Pod can be deleted - \u2705 Instance terminates</p>"},{"location":"development/testing/#example-smoke-test-script","title":"Example: Smoke Test Script","text":"<pre><code>#!/bin/bash\n# scripts/smoke-test.sh\n\nset -e\n\necho \"\ud83d\udd0d Running ORCA smoke tests...\"\n\n# 1. Check ORCA is running\necho \"Checking ORCA pod...\"\nkubectl get pods -n kube-system -l app=orca | grep Running\n\n# 2. Check virtual node exists\necho \"Checking virtual node...\"\nkubectl get node -l orca.research/provider=aws\n\n# 3. Deploy test pod\necho \"Deploying test pod...\"\nkubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Pod\nmetadata:\n  name: smoke-test-pod\n  annotations:\n    orca.research/instance-type: \"t3.small\"\nspec:\n  nodeSelector:\n    orca.research/provider: \"aws\"\n  containers:\n  - name: test\n    image: busybox\n    command: [\"sh\", \"-c\", \"echo 'Smoke test passed' &amp;&amp; sleep 60\"]\nEOF\n\n# 4. Wait for pod to run\necho \"Waiting for pod to run...\"\nkubectl wait --for=condition=Ready pod/smoke-test-pod --timeout=5m\n\n# 5. Verify instance exists\necho \"Checking EC2 instance...\"\naws ec2 describe-instances \\\n  --filters \"Name=tag:orca.research/pod,Values=default/smoke-test-pod\" \\\n  --query 'Reservations[0].Instances[0].State.Name' \\\n  --output text | grep running\n\n# 6. Cleanup\necho \"Cleaning up...\"\nkubectl delete pod smoke-test-pod --wait=true\n\n# 7. Verify instance terminated\necho \"Verifying cleanup...\"\nsleep 30\naws ec2 describe-instances \\\n  --filters \"Name=tag:orca.research/pod,Values=default/smoke-test-pod\" \\\n  --query 'Reservations[0].Instances[0].State.Name' \\\n  --output text | grep -E 'terminated|shutting-down'\n\necho \"\u2705 Smoke tests passed!\"\n</code></pre> <p>Value: 5-minute test catches 80% of deployment issues.</p>"},{"location":"development/testing/#5-regression-tests-prevent-known-bugs","title":"5. Regression Tests (Prevent Known Bugs)","text":"<p>Purpose: Ensure fixed bugs stay fixed When: CI on every PR, before release Value: Prevents bugs from reappearing</p> <p>Process: 1. Bug is reported 2. Write failing test that reproduces bug 3. Fix bug 4. Test now passes 5. Test prevents regression forever</p>"},{"location":"development/testing/#example-regression-for-issue-42","title":"Example: Regression for Issue #42","text":"<pre><code>// pkg/provider/provider_test.go\n\n// TestIssue42_PodWithNoAnnotations tests the fix for:\n// https://github.com/scttfrdmn/orca/issues/42\n// Bug: ORCA crashed when pod had no annotations\nfunc TestIssue42_PodWithNoAnnotations(t *testing.T) {\n    provider := NewProvider(testConfig())\n\n    pod := &amp;corev1.Pod{\n        ObjectMeta: metav1.ObjectMeta{\n            Name:        \"no-annotations\",\n            Namespace:   \"default\",\n            Annotations: nil,  // This was causing panic\n        },\n        Spec: corev1.PodSpec{\n            Containers: []corev1.Container{{Name: \"test\", Image: \"busybox\"}},\n        },\n    }\n\n    // Should not panic\n    err := provider.CreatePod(context.Background(), pod)\n\n    // Should return error, not panic\n    if err == nil {\n        t.Error(\"expected error for missing annotations, got nil\")\n    }\n    if !strings.Contains(err.Error(), \"missing required annotation\") {\n        t.Errorf(\"expected helpful error message, got: %v\", err)\n    }\n}\n</code></pre> <p>Value: Bug #42 can never come back.</p>"},{"location":"development/testing/#test-coverage","title":"Test Coverage","text":"<p>We track coverage but don't worship it. 80%+ coverage is good. 100% is wasteful.</p> <pre><code># Generate coverage report\nmake coverage\n\n# View in browser\nopen coverage.html\n\n# Fail CI if coverage drops below 80%\ngo test -coverprofile=coverage.txt ./...\ngo tool cover -func=coverage.txt | grep total | awk '{print $3}' | sed 's/%//' | awk '$1 &lt; 80 {exit 1}'\n</code></pre> <p>Coverage priorities: 1. Critical paths: 100% (budget enforcement, instance selection) 2. Common paths: 80%+ (pod creation, deletion) 3. Error handling: 70%+ (various failure modes) 4. Happy paths: 60%+ (basic workflows)</p> <p>Don't cover: - Generated code - Third-party integrations (test with mocks) - Trivial code (simple getters)</p>"},{"location":"development/testing/#testing-tools","title":"Testing Tools","text":""},{"location":"development/testing/#mocking-aws-sdk","title":"Mocking AWS SDK","text":"<pre><code>// internal/aws/mock.go\n\ntype MockEC2Client struct {\n    CreateInstanceFunc    func(context.Context, *ec2.RunInstancesInput) (*ec2.RunInstancesOutput, error)\n    TerminateInstanceFunc func(context.Context, *ec2.TerminateInstancesInput) (*ec2.TerminateInstancesOutput, error)\n}\n\nfunc (m *MockEC2Client) RunInstances(ctx context.Context, input *ec2.RunInstancesInput, opts ...func(*ec2.Options)) (*ec2.RunInstancesOutput, error) {\n    if m.CreateInstanceFunc != nil {\n        return m.CreateInstanceFunc(ctx, input)\n    }\n    return &amp;ec2.RunInstancesOutput{\n        Instances: []types.Instance{\n            {InstanceId: aws.String(\"i-mock123\")},\n        },\n    }, nil\n}\n</code></pre>"},{"location":"development/testing/#test-fixtures","title":"Test Fixtures","text":"<pre><code>// pkg/testing/fixtures.go\n\n// CreateTestPod creates a pod for testing\nfunc CreateTestPod(name, instanceType string) *corev1.Pod {\n    return &amp;corev1.Pod{\n        ObjectMeta: metav1.ObjectMeta{\n            Name:      name,\n            Namespace: \"default\",\n            Annotations: map[string]string{\n                AnnotationInstanceType: instanceType,\n            },\n        },\n        Spec: corev1.PodSpec{\n            Containers: []corev1.Container{\n                {Name: \"test\", Image: \"busybox\"},\n            },\n        },\n    }\n}\n</code></pre>"},{"location":"development/testing/#table-driven-tests","title":"Table-Driven Tests","text":"<pre><code>func TestInstanceSelection(t *testing.T) {\n    tests := []struct {\n        name     string\n        input    *corev1.Pod\n        expected string\n        wantErr  bool\n    }{\n        // Test cases here\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            // Test logic here\n        })\n    }\n}\n</code></pre>"},{"location":"development/testing/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"development/testing/#github-actions-workflow","title":"GitHub Actions Workflow","text":"<pre><code># .github/workflows/test.yml\n\nname: Tests\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-go@v5\n        with:\n          go-version: '1.21'\n      - name: Lint\n        uses: golangci/golangci-lint-action@v4\n        with:\n          version: latest\n\n  unit-test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-go@v5\n        with:\n          go-version: '1.21'\n      - name: Run unit tests\n        run: make test\n      - name: Upload coverage\n        uses: codecov/codecov-action@v4\n        with:\n          files: ./coverage.txt\n\n  integration-test:\n    runs-on: ubuntu-latest\n    if: github.event_name == 'push' &amp;&amp; github.ref == 'refs/heads/main'\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-go@v5\n        with:\n          go-version: '1.21'\n      - name: Configure AWS\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n          aws-region: us-west-2\n      - name: Run integration tests\n        run: make integration-test\n\n  smoke-test:\n    runs-on: ubuntu-latest\n    needs: [unit-test]\n    if: github.ref == 'refs/heads/main'\n    steps:\n      - uses: actions/checkout@v4\n      - name: Create kind cluster\n        uses: helm/kind-action@v1\n      - name: Build and deploy ORCA\n        run: |\n          make docker-build\n          kind load docker-image orca:latest\n          kubectl apply -f deploy/kubernetes/\n      - name: Run smoke tests\n        run: ./scripts/smoke-test.sh\n</code></pre>"},{"location":"development/testing/#test-organization","title":"Test Organization","text":"<pre><code>orca/\n\u251c\u2500\u2500 pkg/\n\u2502   \u251c\u2500\u2500 provider/\n\u2502   \u2502   \u251c\u2500\u2500 provider.go\n\u2502   \u2502   \u251c\u2500\u2500 provider_test.go      # Unit tests\n\u2502   \u2502   \u2514\u2500\u2500 provider_integration_test.go  # Integration tests\n\u2502   \u251c\u2500\u2500 instances/\n\u2502   \u2502   \u251c\u2500\u2500 selector.go\n\u2502   \u2502   \u2514\u2500\u2500 selector_test.go\n\u2502   \u2514\u2500\u2500 budget/\n\u2502       \u251c\u2500\u2500 enforcer.go\n\u2502       \u2514\u2500\u2500 enforcer_test.go\n\u251c\u2500\u2500 internal/\n\u2502   \u2514\u2500\u2500 aws/\n\u2502       \u251c\u2500\u2500 client.go\n\u2502       \u251c\u2500\u2500 client_test.go\n\u2502       \u251c\u2500\u2500 client_integration_test.go\n\u2502       \u2514\u2500\u2500 mock.go               # Mock implementations\n\u251c\u2500\u2500 scripts/\n\u2502   \u251c\u2500\u2500 smoke-test.sh             # Smoke tests\n\u2502   \u2514\u2500\u2500 regression-test.sh        # Regression suite\n\u2514\u2500\u2500 tests/\n    \u251c\u2500\u2500 fixtures/                 # Test fixtures\n    \u2514\u2500\u2500 e2e/                      # End-to-end tests\n</code></pre>"},{"location":"development/testing/#testing-checklist","title":"Testing Checklist","text":"<p>Before merging a PR:</p> <ul> <li> <code>make lint</code> passes</li> <li> <code>make test</code> passes with &gt;80% coverage</li> <li> Integration tests pass (if touching AWS code)</li> <li> Smoke test passes (if changing core logic)</li> <li> Added regression test (if fixing bug)</li> <li> Updated test documentation (if adding new test patterns)</li> </ul> <p>Before releasing:</p> <ul> <li> All CI tests pass</li> <li> Smoke tests pass on kind</li> <li> Smoke tests pass on EKS (if available)</li> <li> Manual testing of new features</li> <li> Regression suite passes</li> <li> Performance tests pass (if applicable)</li> </ul>"},{"location":"development/testing/#performance-testing","title":"Performance Testing","text":"<p>For features impacting performance:</p> <pre><code>func BenchmarkInstanceSelection(b *testing.B) {\n    selector := NewExplicitSelector()\n    pod := CreateTestPod(\"test\", \"p5.48xlarge\")\n\n    b.ResetTimer()\n    for i := 0; i &lt; b.N; i++ {\n        _, err := selector.Select(pod)\n        if err != nil {\n            b.Fatal(err)\n        }\n    }\n}\n</code></pre> <p>Run with: <pre><code>go test -bench=. -benchmem ./pkg/instances/\n</code></pre></p>"},{"location":"development/testing/#summary","title":"Summary","text":"<p>Our testing approach:</p> <ol> <li>Lint: Catch mistakes early (seconds)</li> <li>Unit tests: Fast feedback (milliseconds)</li> <li>Integration tests: Validate AWS (minutes, limited runs)</li> <li>Smoke tests: Deployment validation (5 minutes)</li> <li>Regression tests: Keep bugs fixed (continuous)</li> </ol> <p>Every test provides clear value. No busywork. Focus on preventing real bugs and enabling safe refactoring.</p> <p>Test pyramid: <pre><code>        /\\\n       /  \\      E2E Tests (few, slow, expensive)\n      /    \\\n     /------\\    Integration Tests (some, moderate)\n    /        \\\n   /----------\\  Unit Tests (many, fast, cheap)\n  /------------\\\n /   Linting   \\ Static Analysis (everywhere, instant)\n/________________\\\n</code></pre></p> <p>Most value comes from the bottom. Write more unit tests, fewer integration tests, minimal E2E tests.</p>"},{"location":"getting-started/","title":"Getting Started with ORCA","text":"<p>Welcome to ORCA! This guide will help you get started with bursting Kubernetes workloads to AWS.</p>"},{"location":"getting-started/#overview","title":"Overview","text":"<p>ORCA (Orchestration for Research Cloud Access) is a Kubernetes Virtual Kubelet provider that extends your cluster's capacity to AWS EC2 instances.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>Kubernetes cluster (v1.28+)</li> <li>AWS account with appropriate permissions</li> <li>kubectl configured to access your cluster</li> <li>Basic understanding of Kubernetes pods and nodes</li> </ul>"},{"location":"getting-started/#quick-links","title":"Quick Links","text":"<ul> <li>Quick Start Guide - Get ORCA running in 10 minutes</li> <li>Installation - Detailed installation instructions  </li> <li>Configuration - Configure ORCA for your environment</li> <li>First Pod - Deploy your first bursted workload</li> </ul>"},{"location":"getting-started/#what-youll-learn","title":"What You'll Learn","text":"<ol> <li>How to install and configure ORCA</li> <li>How to burst pods to AWS</li> <li>How to select EC2 instance types</li> <li>How to monitor and troubleshoot</li> </ol> <p>Let's get started!</p>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>Configure ORCA for your AWS environment and research workloads.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"getting-started/configuration/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"getting-started/configuration/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"getting-started/first-pod/","title":"Your First Bursted Pod","text":"<p>Deploy your first pod to AWS using ORCA.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"getting-started/first-pod/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"getting-started/first-pod/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>Detailed instructions for installing ORCA in your Kubernetes cluster.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"getting-started/installation/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"getting-started/installation/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"getting-started/quick-start/","title":"ORCA Quick Start Guide","text":"<p>This guide will help you get ORCA up and running in your Kubernetes cluster.</p>"},{"location":"getting-started/quick-start/#prerequisites","title":"Prerequisites","text":"<ul> <li>Kubernetes cluster (1.28+)</li> <li>AWS account with appropriate permissions</li> <li>kubectl configured to access your cluster</li> <li>Go 1.21+ (if building from source)</li> </ul>"},{"location":"getting-started/quick-start/#installation-steps","title":"Installation Steps","text":""},{"location":"getting-started/quick-start/#1-build-orca","title":"1. Build ORCA","text":"<pre><code># Clone the repository\ngit clone https://github.com/scttfrdmn/orca.git\ncd orca\n\n# Build the binary\ngo build -o orca ./cmd/orca\n\n# Or build with version info\nVERSION=$(git describe --tags --always --dirty)\nGIT_COMMIT=$(git rev-parse HEAD)\nBUILD_DATE=$(date -u +%Y-%m-%dT%H:%M:%SZ)\n\ngo build \\\n  -ldflags=\"-X main.version=${VERSION} -X main.gitCommit=${GIT_COMMIT} -X main.buildDate=${BUILD_DATE}\" \\\n  -o orca \\\n  ./cmd/orca\n</code></pre>"},{"location":"getting-started/quick-start/#2-configure-aws-credentials","title":"2. Configure AWS Credentials","text":"<p>ORCA needs AWS credentials to create EC2 instances. Three options:</p> <p>Option A: AWS Profile (Development) <pre><code>export AWS_PROFILE=orca\n./orca --config config.yaml --kubeconfig ~/.kube/config\n</code></pre></p> <p>Option B: Environment Variables <pre><code>export AWS_ACCESS_KEY_ID=AKIA...\nexport AWS_SECRET_ACCESS_KEY=...\nexport AWS_REGION=us-west-2\n</code></pre></p> <p>Option C: IRSA (Production - Recommended) Create IAM role and service account (see deploy/README.md)</p>"},{"location":"getting-started/quick-start/#3-create-configuration-file","title":"3. Create Configuration File","text":"<p>Create <code>config.yaml</code>:</p> <pre><code>aws:\n  region: us-west-2\n  vpcID: vpc-xxxxx\n  subnetID: subnet-xxxxx\n  securityGroupIDs:\n    - sg-xxxxx\n  tags:\n    Environment: production\n    Project: orca\n\nnode:\n  name: orca-aws-node\n  labels:\n    orca.research/provider: \"aws\"\n    orca.research/region: \"us-west-2\"\n  taints:\n    - key: orca.research/burst-node\n      value: \"true\"\n      effect: NoSchedule\n  cpu: \"1000\"\n  memory: \"4Ti\"\n  pods: \"1000\"\n  gpu: \"100\"\n\ninstances:\n  selectionMode: explicit\n  defaultLaunchType: on-demand\n\nlogging:\n  level: info\n  format: json\n\nmetrics:\n  enabled: true\n  port: 8080\n  path: /metrics\n</code></pre>"},{"location":"getting-started/quick-start/#4-run-orca-locally-testing","title":"4. Run ORCA Locally (Testing)","text":"<pre><code># Start ORCA\n./orca \\\n  --config config.yaml \\\n  --kubeconfig ~/.kube/config \\\n  --namespace kube-system \\\n  --log-level debug\n\n# You should see:\n# {\"level\":\"info\",\"time\":\"...\",\"message\":\"Starting ORCA\",\"version\":\"...\"}\n# {\"level\":\"info\",\"message\":\"Starting HTTP server\",\"port\":8080}\n# {\"level\":\"info\",\"message\":\"Starting ORCA Virtual Kubelet node\"}\n# {\"level\":\"info\",\"message\":\"ORCA is running. Press Ctrl+C to stop.\",\"http_port\":8080}\n</code></pre>"},{"location":"getting-started/quick-start/#5-verify-node-registration","title":"5. Verify Node Registration","text":"<p>In another terminal:</p> <pre><code># Check that orca-aws-node appears\nkubectl get nodes\n\n# Should show:\n# NAME              STATUS   ROLES    AGE   VERSION\n# orca-aws-node     Ready    &lt;none&gt;   10s   v1.0.0-orca\n# ...\n\n# Check node details\nkubectl describe node orca-aws-node\n</code></pre>"},{"location":"getting-started/quick-start/#6-deploy-a-test-pod","title":"6. Deploy a Test Pod","text":"<p>Create <code>test-pod.yaml</code>:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-burst\n  annotations:\n    orca.research/instance-type: \"t3.small\"\nspec:\n  nodeSelector:\n    orca.research/provider: \"aws\"\n  tolerations:\n    - key: orca.research/burst-node\n      operator: Equal\n      value: \"true\"\n      effect: NoSchedule\n  containers:\n    - name: test\n      image: nginx:latest\n      ports:\n        - containerPort: 80\n</code></pre> <p>Deploy and watch:</p> <pre><code># Deploy pod\nkubectl apply -f test-pod.yaml\n\n# Watch pod status\nkubectl get pods -w\n\n# You should see:\n# test-burst   0/1     Pending   0          1s\n# test-burst   0/1     Pending   0          5s\n# test-burst   0/1     Running   0          65s  # After EC2 instance starts\n</code></pre>"},{"location":"getting-started/quick-start/#7-verify-ec2-instance-created","title":"7. Verify EC2 Instance Created","text":"<pre><code># List ORCA-managed instances\naws ec2 describe-instances \\\n  --filters \"Name=tag:ManagedBy,Values=ORCA\" \\\n  --query 'Reservations[*].Instances[*].[InstanceId,InstanceType,State.Name,Tags[?Key==`Name`].Value|[0]]' \\\n  --output table\n\n# Should show:\n# |  i-0123456789abcdef  |  t3.small  |  running  |  orca-default-test-burst  |\n</code></pre>"},{"location":"getting-started/quick-start/#8-test-health-checks","title":"8. Test Health Checks","text":"<pre><code># Liveness check\ncurl http://localhost:8080/healthz\n# {\"status\":\"ok\",\"service\":\"orca\"}\n\n# Readiness check  \ncurl http://localhost:8080/readyz\n# {\"status\":\"ready\",\"service\":\"orca\"}\n\n# Prometheus metrics\ncurl http://localhost:8080/metrics\n# HELP go_goroutines Number of goroutines that currently exist.\n# TYPE go_goroutines gauge\n# go_goroutines 42\n# ...\n</code></pre>"},{"location":"getting-started/quick-start/#9-clean-up","title":"9. Clean Up","text":"<pre><code># Delete the test pod\nkubectl delete pod test-burst\n\n# The EC2 instance will be automatically terminated\n\n# Stop ORCA\n# Press Ctrl+C in the ORCA terminal\n\n# Verify instance terminated\naws ec2 describe-instances \\\n  --filters \"Name=tag:ManagedBy,Values=ORCA\" \\\n  --query 'Reservations[*].Instances[*].State.Name'\n</code></pre>"},{"location":"getting-started/quick-start/#production-deployment","title":"Production Deployment","text":"<p>For production deployment as a Kubernetes Deployment:</p>"},{"location":"getting-started/quick-start/#1-create-namespace","title":"1. Create Namespace","text":"<pre><code>kubectl create namespace orca-system\n</code></pre>"},{"location":"getting-started/quick-start/#2-create-rbac-resources","title":"2. Create RBAC Resources","text":"<pre><code>apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: orca\n  namespace: orca-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: orca-role\nrules:\n  - apiGroups: [\"\"]\n    resources: [\"nodes\", \"nodes/status\"]\n    verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n  - apiGroups: [\"\"]\n    resources: [\"pods\", \"pods/status\"]\n    verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n  - apiGroups: [\"coordination.k8s.io\"]\n    resources: [\"leases\"]\n    verbs: [\"get\", \"create\", \"update\", \"patch\", \"delete\", \"list\", \"watch\"]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: orca-binding\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: orca-role\nsubjects:\n  - kind: ServiceAccount\n    name: orca\n    namespace: orca-system\n</code></pre>"},{"location":"getting-started/quick-start/#3-create-configmap","title":"3. Create ConfigMap","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: orca-config\n  namespace: orca-system\ndata:\n  config.yaml: |\n    aws:\n      region: us-west-2\n      vpcID: vpc-xxxxx\n      subnetID: subnet-xxxxx\n      securityGroupIDs:\n        - sg-xxxxx\n      tags:\n        Environment: production\n        Project: orca\n    node:\n      name: orca-aws-node\n      # ... rest of config\n</code></pre>"},{"location":"getting-started/quick-start/#4-create-deployment","title":"4. Create Deployment","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: orca\n  namespace: orca-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: orca\n  template:\n    metadata:\n      labels:\n        app: orca\n    spec:\n      serviceAccountName: orca\n      containers:\n        - name: orca\n          image: orca:latest  # Build and push your image\n          command:\n            - /orca\n          args:\n            - --config=/config/config.yaml\n            - --namespace=orca-system\n          volumeMounts:\n            - name: config\n              mountPath: /config\n          ports:\n            - name: http\n              containerPort: 8080\n          livenessProbe:\n            httpGet:\n              path: /healthz\n              port: 8080\n            initialDelaySeconds: 10\n            periodSeconds: 30\n          readinessProbe:\n            httpGet:\n              path: /readyz\n              port: 8080\n            initialDelaySeconds: 5\n            periodSeconds: 10\n          resources:\n            requests:\n              cpu: 100m\n              memory: 128Mi\n            limits:\n              cpu: 500m\n              memory: 512Mi\n      volumes:\n        - name: config\n          configMap:\n            name: orca-config\n</code></pre>"},{"location":"getting-started/quick-start/#5-deploy","title":"5. Deploy","text":"<pre><code>kubectl apply -f deploy/\n</code></pre>"},{"location":"getting-started/quick-start/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/quick-start/#node-not-appearing","title":"Node Not Appearing","text":"<pre><code># Check ORCA logs\nkubectl logs -n orca-system deployment/orca\n\n# Check RBAC permissions\nkubectl auth can-i create nodes --as=system:serviceaccount:orca-system:orca\n</code></pre>"},{"location":"getting-started/quick-start/#pods-stuck-in-pending","title":"Pods Stuck in Pending","text":"<pre><code># Check pod events\nkubectl describe pod &lt;pod-name&gt;\n\n# Check ORCA logs for instance creation errors\nkubectl logs -n orca-system deployment/orca | grep \"CreateInstance\"\n\n# Verify AWS credentials\nkubectl exec -n orca-system deployment/orca -- env | grep AWS\n</code></pre>"},{"location":"getting-started/quick-start/#ec2-instances-not-terminating","title":"EC2 Instances Not Terminating","text":"<pre><code># Check ORCA logs\nkubectl logs -n orca-system deployment/orca | grep \"DeletePod\"\n\n# Manually check instances\naws ec2 describe-instances --filters \"Name=tag:ManagedBy,Values=ORCA\"\n\n# Manually terminate if needed\naws ec2 terminate-instances --instance-ids i-xxxxx\n</code></pre>"},{"location":"getting-started/quick-start/#next-steps","title":"Next Steps","text":"<ul> <li>GPU Training Example</li> <li>Spot Instance Example</li> <li>Architecture Documentation</li> <li>Virtual Kubelet Integration</li> <li>Instance Selection Guide</li> </ul>"},{"location":"getting-started/quick-start/#getting-help","title":"Getting Help","text":"<ul> <li>GitHub Issues: https://github.com/scttfrdmn/orca/issues</li> <li>Documentation: https://github.com/scttfrdmn/orca/tree/main/docs</li> </ul>"},{"location":"user-guide/","title":"User Guide","text":"<p>Comprehensive guide to using ORCA for research computing workloads.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"user-guide/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"user-guide/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"user-guide/capacity-reservations/","title":"AWS Capacity Reservations for ML Workloads","text":""},{"location":"user-guide/capacity-reservations/#critical-requirement-for-modern-gpus","title":"\u26a0\ufe0f Critical Requirement for Modern GPUs","text":"<p>IMPORTANT: AWS Capacity Reservations are not optional for modern NVIDIA GPU instances. They are effectively required to get access to recent GPU hardware (P5, P4d, P4de, G6e).</p> <p>Reality of AWS GPU Availability (October 2025): - P6.48xlarge (Blackwell B200): Latest generation, Capacity Reservations required - P5e.48xlarge (H200 141GB): Capacity Reservations required - P5.48xlarge (H100 80GB): Virtually impossible without Capacity Reservations - P4de.24xlarge (A100 80GB): Capacity Reservations required in most regions - P4d.24xlarge (A100 40GB): Extremely limited on-demand availability - G6e.48xlarge (L40S): Better availability but still constrained during peak - G6.48xlarge (L4): More available but still benefits from reservations</p> <p>Without Capacity Reservations: - <code>InsufficientInstanceCapacity</code> errors are the norm, not the exception - May wait hours/days for spot instances to become available - On-demand launches fail even when willing to pay full price - Cannot plan or schedule research workloads with confidence</p> <p>With Capacity Reservations: - Guaranteed access to reserved capacity - Launch instances immediately when needed - Can schedule and plan research timelines - Essential for any serious ML/AI research</p> <p>Conclusion: For ORCA to be viable for GPU-intensive research, Capacity Reservations support must be a top priority, not a \"nice to have\" feature.</p>"},{"location":"user-guide/capacity-reservations/#what-are-capacity-reservations","title":"What are Capacity Reservations?","text":""},{"location":"user-guide/capacity-reservations/#on-demand-capacity-reservations-odcrs","title":"On-Demand Capacity Reservations (ODCRs)","text":"<p>On-Demand Capacity Reservations let you reserve compute capacity for your EC2 instances in a specific Availability Zone for any duration. This ensures you have access to instances when you need them.</p> <p>Key Benefits: - Guaranteed Availability: Reserve P5, P4d, or other GPU instances in advance - No Commitment: Can be created/canceled anytime (billed when active) - Combine with Savings Plans: Use reserved capacity with spot pricing - Avoid \"InsufficientInstanceCapacity\": Never fail to launch due to capacity constraints</p>"},{"location":"user-guide/capacity-reservations/#capacity-blocks-for-ml","title":"Capacity Blocks for ML","text":"<p>Capacity Blocks for ML provide reserved GPU capacity for future, defined time periods (days or weeks in advance).</p> <p>Key Benefits: - Planned Workloads: Reserve P5.48xlarge months in advance for training - Cost Predictability: Fixed cost for entire reservation period - Guaranteed Access: Lock in capacity during high-demand periods - Bulk Reservations: Reserve multiple instances for distributed training</p>"},{"location":"user-guide/capacity-reservations/#use-cases","title":"Use Cases","text":""},{"location":"user-guide/capacity-reservations/#1-large-model-training","title":"1. Large Model Training","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: llm-training\n  annotations:\n    orca.research/instance-type: \"p5.48xlarge\"\n    orca.research/capacity-reservation-id: \"cr-0123456789abcdef0\"\n    orca.research/launch-type: \"on-demand\"\nspec:\n  # ... rest of spec\n</code></pre> <p>Scenario: Training a 70B parameter model over 2 weeks - Solution: Create ODCR for p5.48xlarge for 2 weeks - Benefit: Guaranteed access to 8x H100 GPUs, no interruptions - Cost: Pay for reservation + on-demand pricing</p>"},{"location":"user-guide/capacity-reservations/#2-scheduled-batch-jobs","title":"2. Scheduled Batch Jobs","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: batch-inference\n  annotations:\n    orca.research/instance-type: \"g5.xlarge\"\n    orca.research/capacity-reservation-preference: \"open\"\nspec:\n  # ... rest of spec\n</code></pre> <p>Scenario: Daily inference jobs that must complete by 8am - Solution: Create ODCR for daily 12am-8am window - Benefit: Jobs never fail due to capacity - Cost: Only pay for reservation hours (8 hours/day)</p>"},{"location":"user-guide/capacity-reservations/#3-multi-week-research-projects","title":"3. Multi-Week Research Projects","text":"<p>Scenario: Research team needs 16x P4d.24xlarge for 4-week project - Solution: Purchase Capacity Block 2 months in advance - Benefit: Lock in capacity, predictable costs, no capacity anxiety - Cost: Fixed upfront cost for entire 4-week period</p>"},{"location":"user-guide/capacity-reservations/#pricing-model","title":"Pricing Model","text":""},{"location":"user-guide/capacity-reservations/#odcr-pricing","title":"ODCR Pricing","text":"<pre><code>Total Cost = Reservation Fee + Instance Usage\n</code></pre> <ul> <li>Reservation Fee: Charged per hour reservation is active</li> <li>Instance Usage: Standard on-demand or spot pricing when running</li> <li>Cancellation: Can cancel anytime, stop paying reservation fee</li> </ul> <p>Example: P5.48xlarge (H100) ODCR - ODCR fee: ~\\(1-2/hour (varies by region) - On-demand: ~\\)98/hour when instance running - Total when running: ~\\(99-100/hour - Total when idle: ~\\)1-2/hour (reservation only)</p> <p>Example: P6.48xlarge (B200) ODCR (2025 pricing) - ODCR fee: ~\\(2-3/hour (varies by region) - On-demand: ~\\)115/hour when instance running (estimated) - Total when running: ~\\(117-118/hour - Total when idle: ~\\)2-3/hour (reservation only)</p>"},{"location":"user-guide/capacity-reservations/#capacity-blocks-pricing","title":"Capacity Blocks Pricing","text":"<pre><code>Total Cost = Fixed Block Cost (paid upfront)\n</code></pre> <ul> <li>Fixed Cost: Single payment for entire reservation period</li> <li>No Additional Charges: Instance usage included in block cost</li> <li>Commit to Duration: Cannot cancel once purchased</li> </ul> <p>Example: P5.48xlarge Capacity Block - 2-week block: ~\\(32,000-35,000 (typical) - Equivalent to: ~\\)95-100/hour over 336 hours - Advantage: Guaranteed capacity during high-demand periods</p>"},{"location":"user-guide/capacity-reservations/#implementation-plan-future","title":"Implementation Plan (Future)","text":""},{"location":"user-guide/capacity-reservations/#phase-1-odcr-support","title":"Phase 1: ODCR Support","text":"<pre><code>// internal/aws/capacity.go\ntype CapacityReservation struct {\n    ID               string\n    InstanceType     string\n    AvailabilityZone string\n    TotalInstances   int\n    AvailableInstances int\n    State            string\n}\n\n// Check for available capacity in reservations\nfunc (c *Client) GetAvailableCapacityReservations(\n    ctx context.Context,\n    instanceType string,\n) ([]*CapacityReservation, error)\n</code></pre>"},{"location":"user-guide/capacity-reservations/#phase-2-pod-annotations","title":"Phase 2: Pod Annotations","text":"<pre><code>annotations:\n  # Target specific reservation\n  orca.research/capacity-reservation-id: \"cr-0123456789abcdef0\"\n\n  # Prefer reservations but allow on-demand if none available\n  orca.research/capacity-reservation-preference: \"open\"\n\n  # Require reservation, fail if none available\n  orca.research/capacity-reservation-preference: \"targeted\"\n\n  # Use Capacity Block\n  orca.research/capacity-block-id: \"cb-0123456789abcdef0\"\n</code></pre>"},{"location":"user-guide/capacity-reservations/#phase-3-automatic-discovery","title":"Phase 3: Automatic Discovery","text":"<p>ORCA will automatically discover and match pods to available capacity reservations:</p> <ol> <li>Pod requests p5.48xlarge</li> <li>ORCA queries for available ODCRs/Capacity Blocks</li> <li>If match found, use reservation</li> <li>If no match, fall back to on-demand/spot</li> </ol>"},{"location":"user-guide/capacity-reservations/#phase-4-reservation-management","title":"Phase 4: Reservation Management","text":"<pre><code># CLI tool for managing reservations\norca-capacity list\norca-capacity create p5.48xlarge --count 4 --duration 7d\norca-capacity delete cr-0123456789abcdef0\norca-capacity stats  # Show utilization\n</code></pre>"},{"location":"user-guide/capacity-reservations/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/capacity-reservations/#1-use-odcrs-for-critical-workloads","title":"1. Use ODCRs for Critical Workloads","text":"<p>Reserve capacity for: - \u274c Short experiments (&lt; 1 hour) - use spot - \u2705 Long training runs (&gt; 8 hours) - use ODCR - \u2705 Production inference endpoints - use ODCR - \u2705 Time-sensitive research deadlines - use ODCR</p>"},{"location":"user-guide/capacity-reservations/#2-combine-with-spot-instances","title":"2. Combine with Spot Instances","text":"<pre><code>annotations:\n  orca.research/instance-type: \"p5.48xlarge\"\n  orca.research/capacity-reservation-id: \"cr-xxx\"\n  orca.research/launch-type: \"spot\"\n</code></pre> <p>Strategy: - Reserve capacity to guarantee availability - Use spot pricing for 70% cost savings - Best of both worlds: availability + cost optimization</p>"},{"location":"user-guide/capacity-reservations/#3-monitor-utilization","title":"3. Monitor Utilization","text":"<p>Track reservation usage: - High utilization (&gt;80%): Good ROI, consider more reservations - Low utilization (&lt;30%): Wasting money, cancel or reduce - Peak usage patterns: Adjust reservation schedule</p>"},{"location":"user-guide/capacity-reservations/#4-plan-ahead-for-capacity-blocks","title":"4. Plan Ahead for Capacity Blocks","text":"<p>Capacity Blocks sell out during peak periods: - Plan 2-3 months ahead for major training runs - Book early for popular instances (P5.48xlarge) - Consider multiple AZs if primary is sold out</p>"},{"location":"user-guide/capacity-reservations/#aws-cli-examples","title":"AWS CLI Examples","text":""},{"location":"user-guide/capacity-reservations/#create-on-demand-capacity-reservation","title":"Create On-Demand Capacity Reservation","text":"<pre><code># Create ODCR for 4x p5.48xlarge\naws ec2 create-capacity-reservation \\\n  --instance-type p5.48xlarge \\\n  --instance-platform Linux/UNIX \\\n  --availability-zone us-east-1a \\\n  --instance-count 4 \\\n  --instance-match-criteria targeted \\\n  --end-date-type unlimited\n\n# List reservations\naws ec2 describe-capacity-reservations\n\n# Modify reservation (increase count)\naws ec2 modify-capacity-reservation \\\n  --capacity-reservation-id cr-xxx \\\n  --instance-count 8\n\n# Cancel reservation\naws ec2 cancel-capacity-reservation \\\n  --capacity-reservation-id cr-xxx\n</code></pre>"},{"location":"user-guide/capacity-reservations/#purchase-capacity-block","title":"Purchase Capacity Block","text":"<pre><code># Find available capacity blocks\naws ec2 describe-capacity-block-offerings \\\n  --instance-type p5.48xlarge \\\n  --instance-count 4 \\\n  --capacity-duration 336  # hours (2 weeks)\n\n# Purchase capacity block\naws ec2 purchase-capacity-block \\\n  --capacity-block-offering-id cbo-xxx \\\n  --instance-platform Linux/UNIX\n</code></pre>"},{"location":"user-guide/capacity-reservations/#cost-optimization-strategies","title":"Cost Optimization Strategies","text":""},{"location":"user-guide/capacity-reservations/#strategy-1-time-based-reservations","title":"Strategy 1: Time-Based Reservations","text":"<p>Scenario: Training jobs run 8am-8pm weekdays</p> <pre><code># Automation: Create ODCR weekdays 8am, cancel 8pm\n# Cost savings: Only pay 12 hours/day * 5 days = 60 hours/week\n# vs 168 hours/week for always-on reservation\n</code></pre>"},{"location":"user-guide/capacity-reservations/#strategy-2-burst-reserved","title":"Strategy 2: Burst + Reserved","text":"<p>Normal load: Use spot instances Peak demand: Fail over to reserved capacity</p> <pre><code>annotations:\n  orca.research/launch-type: \"spot\"\n  orca.research/capacity-reservation-preference: \"open\"\n</code></pre>"},{"location":"user-guide/capacity-reservations/#strategy-3-team-sharing","title":"Strategy 3: Team Sharing","text":"<p>Multiple teams sharing reservation pool: - Create organizational ODCR pool - Teams request from pool via ORCA - Track usage per team with budget-namespace annotation - Charge back based on utilization</p>"},{"location":"user-guide/capacity-reservations/#future-integration-with-orca","title":"Future: Integration with ORCA","text":""},{"location":"user-guide/capacity-reservations/#configuration","title":"Configuration","text":"<pre><code># config.yaml\naws:\n  capacityReservations:\n    enabled: true\n    autoDiscovery: true\n    preferenceDefault: \"open\"\n\n    # Specific reservations for workload types\n    reservations:\n      - id: \"cr-training-p5\"\n        instanceType: \"p5.48xlarge\"\n        workloadType: \"training\"\n\n      - id: \"cr-inference-g5\"\n        instanceType: \"g5.xlarge\"\n        workloadType: \"inference\"\n</code></pre>"},{"location":"user-guide/capacity-reservations/#metrics","title":"Metrics","text":"<p>ORCA will expose capacity reservation metrics:</p> <pre><code>orca_capacity_reservation_total\norca_capacity_reservation_available\norca_capacity_reservation_utilization_percent\norca_capacity_reservation_cost_per_hour\n</code></pre>"},{"location":"user-guide/capacity-reservations/#references","title":"References","text":"<ul> <li>AWS On-Demand Capacity Reservations</li> <li>AWS Capacity Blocks for ML</li> <li>Capacity Reservations Pricing</li> </ul>"},{"location":"user-guide/capacity-reservations/#timeline","title":"Timeline","text":"<p>REVISED PRIORITY: Given that Capacity Reservations are effectively required for modern GPU instances, this feature timeline is accelerated:</p> <ul> <li>Phase 1 (v0.1.0 - Current): Manual ODCR management outside ORCA</li> <li>Users create reservations manually</li> <li>Document workarounds and best practices</li> <li> <p>ORCA can launch into existing reservations if configured</p> </li> <li> <p>Phase 2 (v0.2.0 - CRITICAL PRIORITY): Basic ODCR support</p> </li> <li>Target specific capacity reservations via annotation</li> <li><code>orca.research/capacity-reservation-id</code> support</li> <li>Fail gracefully with clear error if reservation unavailable</li> <li> <p>Document ODCR setup for P5/P4d instances</p> </li> <li> <p>Phase 3 (v0.3.0 - HIGH PRIORITY): Automatic ODCR discovery</p> </li> <li>Query available capacity reservations for instance type</li> <li>Automatic matching and selection</li> <li>Prefer reserved capacity over on-demand</li> <li> <p>Metrics and monitoring for reservation utilization</p> </li> <li> <p>Phase 4 (v0.4.0): Capacity Blocks support</p> </li> <li>Support Capacity Block targeting</li> <li>Plan ahead for scheduled workloads</li> <li> <p>Integration with workload scheduling</p> </li> <li> <p>Phase 5 (v0.5.0): Advanced capacity management</p> </li> <li>ORCA capacity management CLI</li> <li>Automated reservation lifecycle</li> <li>Team-based reservation pools</li> <li>Cost allocation and chargeback</li> </ul> <p>Status: \ud83d\udea8 CRITICAL FEATURE - Phase 2 (v0.2.0) is essential for GPU workloads</p> <p>Current Workaround: Users must manually create ODCRs and configure ORCA to use them. Without this, modern GPU instances (P5, P4d) are effectively unavailable.</p>"},{"location":"user-guide/cost-management/","title":"Cost Management","text":"<p>Managing costs and budgets for bursted workloads.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"user-guide/cost-management/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"user-guide/cost-management/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"user-guide/custom-silicon/","title":"AWS Custom Silicon and FPGA Support","text":"<p>ORCA supports AWS custom silicon accelerators and FPGAs for specialized AI/ML and compute workloads.</p>"},{"location":"user-guide/custom-silicon/#aws-trainium-ai-training","title":"AWS Trainium (AI Training)","text":"<p>AWS Trainium is purpose-built for deep learning training, offering cost-effective training for large language models and other AI workloads.</p>"},{"location":"user-guide/custom-silicon/#trainium-instance-types-2025","title":"Trainium Instance Types (2025)","text":"<ul> <li>Trn2.48xlarge: 16x Trainium2 chips, 192 vCPUs, 2TB RAM</li> <li>~50% cost reduction vs P5 for training</li> <li>Optimized for LLM training</li> <li> <p>NeuronLink interconnect for distributed training</p> </li> <li> <p>Trn2.24xlarge: 8x Trainium2 chips, 96 vCPUs, 1TB RAM</p> </li> <li> <p>Trn1.32xlarge: 16x Trainium1 chips, 128 vCPUs, 512GB RAM (previous generation)</p> </li> <li> <p>Trn1n.32xlarge: 16x Trainium1 chips with enhanced networking</p> </li> </ul>"},{"location":"user-guide/custom-silicon/#example-llm-training-on-trainium","title":"Example: LLM Training on Trainium","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: llm-training-trainium\n  annotations:\n    orca.research/instance-type: \"trn2.48xlarge\"\n    orca.research/launch-type: \"on-demand\"\nspec:\n  nodeSelector:\n    orca.research/provider: \"aws\"\n  tolerations:\n    - key: orca.research/burst-node\n      operator: Equal\n      value: \"true\"\n      effect: NoSchedule\n  containers:\n    - name: trainer\n      image: your-trainium-image:latest\n      resources:\n        requests:\n          aws.amazon.com/neuron: \"16\"  # Request Trainium cores\n        limits:\n          aws.amazon.com/neuron: \"16\"\n</code></pre>"},{"location":"user-guide/custom-silicon/#trainium-benefits","title":"Trainium Benefits","text":"<ul> <li>Cost Optimization: ~50% lower cost per training compared to GPU instances</li> <li>Purpose-Built: Optimized for transformer models and LLMs</li> <li>Scale: NeuronLink provides high-bandwidth interconnect</li> <li>PyTorch Support: AWS Neuron SDK with PyTorch integration</li> <li>JAX Support: Native JAX/Flax support for research</li> </ul>"},{"location":"user-guide/custom-silicon/#when-to-use-trainium","title":"When to Use Trainium","text":"<p>\u2705 Good for: - Large language model training (BERT, GPT, LLaMA, etc.) - Transformer-based models - Cost-sensitive training workloads - Long-running training jobs</p> <p>\u274c Not ideal for: - Models requiring CUDA-specific code - Workloads requiring NVIDIA-specific libraries - Inference (use Inferentia instead) - Short exploratory experiments</p>"},{"location":"user-guide/custom-silicon/#aws-inferentia-ai-inference","title":"AWS Inferentia (AI Inference)","text":"<p>AWS Inferentia is optimized for high-performance, cost-effective ML inference.</p>"},{"location":"user-guide/custom-silicon/#inferentia-instance-types-2025","title":"Inferentia Instance Types (2025)","text":"<ul> <li>Inf2.48xlarge: 12x Inferentia2 chips, 192 vCPUs, 384GB RAM</li> <li>Best price/performance for inference</li> <li> <p>Up to 4x throughput vs Inf1</p> </li> <li> <p>Inf2.24xlarge: 6x Inferentia2 chips, 96 vCPUs, 192GB RAM</p> </li> <li> <p>Inf2.8xlarge: 2x Inferentia2 chips, 32 vCPUs, 64GB RAM</p> </li> <li> <p>Inf1.24xlarge: 16x Inferentia1 chips (previous generation, still supported)</p> </li> </ul>"},{"location":"user-guide/custom-silicon/#example-model-inference-on-inferentia","title":"Example: Model Inference on Inferentia","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: llm-inference\n  annotations:\n    orca.research/instance-type: \"inf2.24xlarge\"\n    orca.research/launch-type: \"on-demand\"\nspec:\n  nodeSelector:\n    orca.research/provider: \"aws\"\n  tolerations:\n    - key: orca.research/burst-node\n      operator: Equal\n      value: \"true\"\n      effect: NoSchedule\n  containers:\n    - name: inference\n      image: your-inferentia-image:latest\n      resources:\n        requests:\n          aws.amazon.com/neuron: \"6\"  # Request Inferentia cores\n        limits:\n          aws.amazon.com/neuron: \"6\"\n</code></pre>"},{"location":"user-guide/custom-silicon/#inferentia-benefits","title":"Inferentia Benefits","text":"<ul> <li>Cost Effective: Up to 70% lower cost per inference vs GPU</li> <li>High Throughput: Optimized for batched inference</li> <li>Low Latency: Purpose-built for production inference</li> <li>Model Support: Broad framework support (PyTorch, TensorFlow, ONNX)</li> </ul>"},{"location":"user-guide/custom-silicon/#when-to-use-inferentia","title":"When to Use Inferentia","text":"<p>\u2705 Good for: - Production inference endpoints - High-throughput batch inference - Cost-sensitive deployments - Latency-critical applications - LLM serving (LLaMA, BERT, T5, etc.)</p> <p>\u274c Not ideal for: - Training workloads (use Trainium or GPUs) - Interactive model development - Models requiring CUDA</p>"},{"location":"user-guide/custom-silicon/#aws-fpgas-custom-acceleration","title":"AWS FPGAs (Custom Acceleration)","text":"<p>FPGAs provide customizable hardware acceleration for specialized compute workloads.</p>"},{"location":"user-guide/custom-silicon/#fpga-instance-types-2025","title":"FPGA Instance Types (2025)","text":"<ul> <li>F2.48xlarge: 8x Xilinx Alveo U250 FPGAs, 192 vCPUs, 2TB RAM</li> <li>Latest generation (F1 retired in 2025)</li> <li>PCIe Gen 4 support</li> <li> <p>Higher memory bandwidth</p> </li> <li> <p>F2.16xlarge: 4x Xilinx Alveo U250 FPGAs, 64 vCPUs, 1TB RAM</p> </li> <li> <p>F2.4xlarge: 1x Xilinx Alveo U250 FPGA, 16 vCPUs, 122GB RAM</p> </li> <li> <p>F2.2xlarge: 1x Xilinx Alveo U250 FPGA, 8 vCPUs, 61GB RAM</p> </li> </ul>"},{"location":"user-guide/custom-silicon/#example-fpga-workload","title":"Example: FPGA Workload","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: fpga-acceleration\n  annotations:\n    orca.research/instance-type: \"f2.16xlarge\"\n    orca.research/launch-type: \"on-demand\"\nspec:\n  nodeSelector:\n    orca.research/provider: \"aws\"\n  tolerations:\n    - key: orca.research/burst-node\n      operator: Equal\n      value: \"true\"\n      effect: NoSchedule\n  containers:\n    - name: fpga-app\n      image: your-fpga-image:latest\n      resources:\n        requests:\n          aws.amazon.com/fpga: \"4\"  # Request FPGAs\n        limits:\n          aws.amazon.com/fpga: \"4\"\n</code></pre>"},{"location":"user-guide/custom-silicon/#fpga-use-cases","title":"FPGA Use Cases","text":"<p>\u2705 Good for: - Custom hardware acceleration - Financial modeling and risk analysis - Genomics and bioinformatics - Video transcoding and processing - Network security and cryptography - Custom ML accelerators - High-frequency trading</p> <p>\u274c Not ideal for: - General-purpose computing - Workloads without FPGA expertise - Short-lived jobs (FPGA programming overhead)</p>"},{"location":"user-guide/custom-silicon/#fpga-development","title":"FPGA Development","text":"<p>FPGAs require specialized development:</p> <ol> <li>AWS FPGA Developer AMI: Pre-configured development environment</li> <li>Xilinx Vitis: FPGA development tools</li> <li>AFI (Amazon FPGA Image): Pre-built or custom FPGA images</li> <li>OpenCL Support: Higher-level FPGA programming</li> </ol>"},{"location":"user-guide/custom-silicon/#comparison-matrix","title":"Comparison Matrix","text":"Feature Trainium Inferentia NVIDIA GPU FPGA Primary Use Training Inference Training/Inference Custom Acceleration Cost Low Very Low High Medium Performance High (Training) High (Inference) Highest Customizable Flexibility Medium Medium High Highest Development PyTorch/JAX PyTorch/TF CUDA/PyTorch Xilinx/OpenCL Time to Deploy Fast Fast Fast Slow (FPGA dev) Availability Good Good Limited Good"},{"location":"user-guide/custom-silicon/#orca-configuration","title":"ORCA Configuration","text":""},{"location":"user-guide/custom-silicon/#instance-selection-examples","title":"Instance Selection Examples","text":"<pre><code>instances:\n  templates:\n    # Training templates\n    llm-training-gpu:\n      instanceType: p6.48xlarge      # NVIDIA B200\n      launchType: spot\n\n    llm-training-trainium:\n      instanceType: trn2.48xlarge    # AWS Trainium2\n      launchType: on-demand\n\n    # Inference templates\n    inference-gpu:\n      instanceType: g6.xlarge        # NVIDIA L4\n      launchType: on-demand\n\n    inference-inferentia:\n      instanceType: inf2.24xlarge    # AWS Inferentia2\n      launchType: on-demand\n\n    # FPGA templates\n    fpga-acceleration:\n      instanceType: f2.16xlarge      # 4x FPGAs\n      launchType: on-demand\n\n  # Allowed instance types\n  allowedInstanceTypes:\n    # Trainium\n    - trn2.48xlarge\n    - trn2.24xlarge\n    - trn1.32xlarge\n    - trn1n.32xlarge\n\n    # Inferentia\n    - inf2.48xlarge\n    - inf2.24xlarge\n    - inf2.8xlarge\n    - inf1.24xlarge\n\n    # FPGA\n    - f2.48xlarge\n    - f2.16xlarge\n    - f2.4xlarge\n    - f2.2xlarge\n</code></pre>"},{"location":"user-guide/custom-silicon/#cost-comparison-approximate-2025-pricing","title":"Cost Comparison (Approximate 2025 Pricing)","text":""},{"location":"user-guide/custom-silicon/#training-workloads","title":"Training Workloads","text":"<ul> <li>P6.48xlarge (8x B200): ~$115/hour</li> <li>P5.48xlarge (8x H100): ~$98/hour</li> <li>Trn2.48xlarge (16x Trainium2): ~$50/hour \u2705 50% savings</li> </ul>"},{"location":"user-guide/custom-silicon/#inference-workloads","title":"Inference Workloads","text":"<ul> <li>G6.xlarge (1x L4): ~$1.20/hour</li> <li>Inf2.24xlarge (6x Inferentia2): ~$8/hour \u2705 Better throughput/cost</li> </ul>"},{"location":"user-guide/custom-silicon/#fpga-workloads","title":"FPGA Workloads","text":"<ul> <li>F2.16xlarge (4x FPGAs): ~$22/hour</li> </ul>"},{"location":"user-guide/custom-silicon/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/custom-silicon/#trainium","title":"Trainium","text":"<ol> <li>Use for Large Models: Best ROI for models &gt;1B parameters</li> <li>Batch Training: Optimize batch sizes for Trainium</li> <li>Distributed Training: Use NeuronLink for multi-node</li> <li>Model Compilation: Pre-compile models with Neuron compiler</li> </ol>"},{"location":"user-guide/custom-silicon/#inferentia","title":"Inferentia","text":"<ol> <li>Batch Inference: Optimize for throughput over latency</li> <li>Model Optimization: Use Neuron compiler optimizations</li> <li>Right-Sizing: Choose instance size based on throughput needs</li> <li>Model Caching: Pre-compile and cache models</li> </ol>"},{"location":"user-guide/custom-silicon/#fpga","title":"FPGA","text":"<ol> <li>Long-Running Jobs: Amortize FPGA programming time</li> <li>Reuse AFIs: Use pre-built Amazon FPGA Images</li> <li>Custom Acceleration: Only when general compute insufficient</li> <li>Development Time: Budget for FPGA development expertise</li> </ol>"},{"location":"user-guide/custom-silicon/#aws-neuron-sdk","title":"AWS Neuron SDK","text":"<p>Both Trainium and Inferentia require the AWS Neuron SDK:</p> <pre><code># Example Dockerfile for Neuron workloads\nFROM public.ecr.aws/neuron/pytorch-training-neuronx:2.1.0-neuronx-py310\n\n# Install dependencies\nRUN pip install transformers datasets\n\n# Copy training code\nCOPY train.py /app/\n\n# Run with Neuron\nCMD [\"neuron-train\", \"train.py\"]\n</code></pre>"},{"location":"user-guide/custom-silicon/#resource-requests","title":"Resource Requests","text":""},{"location":"user-guide/custom-silicon/#trainiuminferentia","title":"Trainium/Inferentia","text":"<pre><code>resources:\n  requests:\n    aws.amazon.com/neuron: \"16\"  # Number of Neuron cores\n  limits:\n    aws.amazon.com/neuron: \"16\"\n</code></pre>"},{"location":"user-guide/custom-silicon/#fpga_1","title":"FPGA","text":"<pre><code>resources:\n  requests:\n    aws.amazon.com/fpga: \"4\"  # Number of FPGAs\n  limits:\n    aws.amazon.com/fpga: \"4\"\n</code></pre>"},{"location":"user-guide/custom-silicon/#future-support","title":"Future Support","text":"<p>ORCA will continue to support AWS custom silicon as new generations are released: - Trainium3 (expected 2026) - Inferentia3 (expected 2026) - Next-gen FPGAs</p>"},{"location":"user-guide/custom-silicon/#references","title":"References","text":"<ul> <li>AWS Trainium</li> <li>AWS Inferentia</li> <li>AWS FPGA Instances</li> <li>AWS Neuron SDK</li> <li>FPGA Developer AMI</li> </ul> <p>Last updated: October 2025</p>"},{"location":"user-guide/gpu-workloads/","title":"GPU Workloads","text":"<p>Running GPU-accelerated AI/ML workloads on AWS.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"user-guide/gpu-workloads/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"user-guide/gpu-workloads/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"user-guide/instance-selection/","title":"Instance Selection","text":"<p>How to select the right EC2 instance type for your workload.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"user-guide/instance-selection/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"user-guide/instance-selection/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"user-guide/spot-instances/","title":"Spot Instances","text":"<p>Using AWS Spot instances for cost-optimized computing.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"user-guide/spot-instances/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"user-guide/spot-instances/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"},{"location":"user-guide/troubleshooting/","title":"Troubleshooting","text":"<p>Common issues and how to resolve them.</p> <p>Documentation In Progress</p> <p>This page is under construction. Check back soon for detailed content!</p>"},{"location":"user-guide/troubleshooting/#coming-soon","title":"Coming Soon","text":"<p>This section will cover:</p> <ul> <li>Key concepts and features</li> <li>Step-by-step instructions</li> <li>Examples and best practices</li> <li>Troubleshooting tips</li> </ul>"},{"location":"user-guide/troubleshooting/#need-help-now","title":"Need Help Now?","text":"<ul> <li>Check our GitHub Issues</li> <li>Join the Discussions</li> <li>Read the README</li> </ul>"}]}