---
apiVersion: v1
kind: Pod
metadata:
  name: gpu-training-job
  namespace: default
  annotations:
    # Latest GPU instance for LLM training
    orca.research/instance-type: "p6.48xlarge"  # 8x B200 GPUs (Blackwell)
    # NOTE: P6 instances require Capacity Reservations
    # orca.research/capacity-reservation-id: "cr-xxxxx"  # v0.2.0+
    # Use spot for cost savings (if available)
    orca.research/launch-type: "spot"
    # Set max spot price
    orca.research/max-spot-price: "35.00"
    # Budget tracking
    orca.research/budget-namespace: "ml-team"
spec:
  nodeSelector:
    orca.research/provider: "aws"

  tolerations:
    - key: orca.research/burst-node
      operator: Equal
      value: "true"
      effect: NoSchedule

  restartPolicy: Never

  containers:
    - name: trainer
      image: nvcr.io/nvidia/pytorch:24.01-py3
      command:
        - python3
        - -c
        - |
          import torch
          print(f"PyTorch version: {torch.__version__}")
          print(f"CUDA available: {torch.cuda.is_available()}")
          print(f"CUDA devices: {torch.cuda.device_count()}")

          if torch.cuda.is_available():
              for i in range(torch.cuda.device_count()):
                  print(f"  Device {i}: {torch.cuda.get_device_name(i)}")

          print("Training simulation for 5 minutes...")
          import time
          time.sleep(300)
          print("Training complete!")

      resources:
        requests:
          cpu: "100"
          memory: "1Ti"
          nvidia.com/gpu: "8"
        limits:
          nvidia.com/gpu: "8"

      env:
        - name: NVIDIA_VISIBLE_DEVICES
          value: "all"
