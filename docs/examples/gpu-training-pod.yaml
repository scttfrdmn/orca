apiVersion: v1
kind: Pod
metadata:
  name: gpu-training-example
  annotations:
    # Explicit instance selection - you control exactly what you get
    orca.research/instance-type: "p5.48xlarge"  # 8x H100 GPUs
    orca.research/launch-type: "spot"           # 70% cost savings
spec:
  nodeSelector:
    orca.research/provider: "aws"
  tolerations:
  - key: orca.research/burst-node
    operator: Equal
    value: "true"
    effect: NoSchedule
  containers:
  - name: trainer
    image: pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime
    command: ["python", "train.py"]
    resources:
      limits:
        nvidia.com/gpu: 8
        memory: "1024Gi"
        cpu: "192"
      requests:
        nvidia.com/gpu: 8
        memory: "1024Gi"
        cpu: "192"
    volumeMounts:
    - name: data
      mountPath: /data
    - name: models
      mountPath: /models
  volumes:
  - name: data
    hostPath:
      path: /mnt/data
      type: Directory
  - name: models
    hostPath:
      path: /mnt/models
      type: Directory
  restartPolicy: Never
